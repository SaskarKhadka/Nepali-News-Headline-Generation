{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d94bfd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-04T06:49:44.524834Z",
     "iopub.status.busy": "2025-05-04T06:49:44.524518Z",
     "iopub.status.idle": "2025-05-04T06:50:03.208451Z",
     "shell.execute_reply": "2025-05-04T06:50:03.207492Z"
    },
    "papermill": {
     "duration": 18.693424,
     "end_time": "2025-05-04T06:50:03.210337",
     "exception": false,
     "start_time": "2025-05-04T06:49:44.516913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Input, Dense, TimeDistributed, Embedding, Concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165f12a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:50:03.224112Z",
     "iopub.status.busy": "2025-05-04T06:50:03.223568Z",
     "iopub.status.idle": "2025-05-04T06:50:03.457328Z",
     "shell.execute_reply": "2025-05-04T06:50:03.456526Z"
    },
    "papermill": {
     "duration": 0.241361,
     "end_time": "2025-05-04T06:50:03.458576",
     "exception": false,
     "start_time": "2025-05-04T06:50:03.217215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# from tensorflow.keras.mixed_precision import set_global_policy\n",
    "# set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c4abfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:50:03.471444Z",
     "iopub.status.busy": "2025-05-04T06:50:03.471202Z",
     "iopub.status.idle": "2025-05-04T06:50:03.766519Z",
     "shell.execute_reply": "2025-05-04T06:50:03.765689Z"
    },
    "papermill": {
     "duration": 0.303105,
     "end_time": "2025-05-04T06:50:03.767815",
     "exception": false,
     "start_time": "2025-05-04T06:50:03.464710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "       tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca8d4c21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:50:03.780636Z",
     "iopub.status.busy": "2025-05-04T06:50:03.780405Z",
     "iopub.status.idle": "2025-05-04T06:50:03.833557Z",
     "shell.execute_reply": "2025-05-04T06:50:03.832704Z"
    },
    "papermill": {
     "duration": 0.060904,
     "end_time": "2025-05-04T06:50:03.834907",
     "exception": false,
     "start_time": "2025-05-04T06:50:03.774003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"/kaggle/input/nepali-summarization-tokenizer/summarization_50000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8925b9a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:50:03.847809Z",
     "iopub.status.busy": "2025-05-04T06:50:03.847569Z",
     "iopub.status.idle": "2025-05-04T06:50:03.851726Z",
     "shell.execute_reply": "2025-05-04T06:50:03.851095Z"
    },
    "papermill": {
     "duration": 0.011749,
     "end_time": "2025-05-04T06:50:03.852975",
     "exception": false,
     "start_time": "2025-05-04T06:50:03.841226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'VOC_SIZE': 50_000,\n",
    "\n",
    "    'ENCODER_SEQUENCE_LENGTH': 256,\n",
    "    'DECODER_SEQUENCE_LENGTH': 12,\n",
    "    \n",
    "    'EMBEDDING_DIMENSION': 100,\n",
    "    \n",
    "    'ENCODER_HIDDEN_DIM': 64,\n",
    "    'DECODER_HIDDEN_DIM': 128,\n",
    "    \n",
    "    'DROPOUT': 0.3,\n",
    "\n",
    "    'BATCH_SIZE': 128,\n",
    "    'EPOCHS': 16,\n",
    "    'EARLY_STOPPING': 3,\n",
    "    'L2_REG': 0.01,\n",
    "    \n",
    "    'LEARNING_RATE': 1e-3,\n",
    "    'GRAD_CLIP': 1.0,\n",
    "\n",
    "    'PAD_TOKEN': '<pad>',\n",
    "    'UNK_TOKEN': '<unk>',\n",
    "    'SOS_TOKEN': '<s>',\n",
    "    'EOS_TOKEN': '</s>',\n",
    "\n",
    "    'PAD_TOKEN_ID': sp.pad_id(),\n",
    "    'UNK_TOKEN_ID': sp.unk_id(),\n",
    "    'SOS_TOKEN_ID': sp.bos_id(),\n",
    "    'EOS_TOKEN_ID': sp.eos_id(),\n",
    "\n",
    "    'ATTENTION_TYPE': 'bahdanau',\n",
    "\n",
    "    'COVERAGE_WEIGHT': 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14d858c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:50:03.865295Z",
     "iopub.status.busy": "2025-05-04T06:50:03.865066Z",
     "iopub.status.idle": "2025-05-04T06:50:05.346474Z",
     "shell.execute_reply": "2025-05-04T06:50:05.345729Z"
    },
    "papermill": {
     "duration": 1.489194,
     "end_time": "2025-05-04T06:50:05.348053",
     "exception": false,
     "start_time": "2025-05-04T06:50:03.858859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv('/kaggle/input/nepali-summarization-set-cleaned/summarization_set_cleaned_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aee6e1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:50:05.361238Z",
     "iopub.status.busy": "2025-05-04T06:50:05.360974Z",
     "iopub.status.idle": "2025-05-04T06:50:05.364177Z",
     "shell.execute_reply": "2025-05-04T06:50:05.363499Z"
    },
    "papermill": {
     "duration": 0.010916,
     "end_time": "2025-05-04T06:50:05.365376",
     "exception": false,
     "start_time": "2025-05-04T06:50:05.354460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_files = {\n",
    "    \"train\": \"/kaggle/input/nepali-summarization-set-cleaned/summarization_set_cleaned_train.csv\",\n",
    "    \"test\": \"/kaggle/input/nepali-summarization-set-cleaned/summarization_set_cleaned_test.csv\",\n",
    "    \"eval\": \"/kaggle/input/nepali-summarization-set-cleaned/summarization_set_cleaned_val.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d71575d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:50:05.379129Z",
     "iopub.status.busy": "2025-05-04T06:50:05.378802Z",
     "iopub.status.idle": "2025-05-04T06:50:05.384709Z",
     "shell.execute_reply": "2025-05-04T06:50:05.383961Z"
    },
    "papermill": {
     "duration": 0.014284,
     "end_time": "2025-05-04T06:50:05.385909",
     "exception": false,
     "start_time": "2025-05-04T06:50:05.371625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch: torch.tensor):\n",
    "    data = {\n",
    "        'encoder_inputs': [],\n",
    "        'decoder_targets': [],\n",
    "    }\n",
    "\n",
    "    for row in batch:\n",
    "        news_encoded = sp.encode(row['news'])\n",
    "        title_encoded = sp.encode(row['title']) + [sp.eos_id()]\n",
    "\n",
    "        if len(news_encoded) >= parameters['ENCODER_SEQUENCE_LENGTH']:\n",
    "            data['encoder_inputs'].append(news_encoded[:parameters['ENCODER_SEQUENCE_LENGTH']])\n",
    "        else:\n",
    "            data['encoder_inputs'].append(news_encoded + [sp.pad_id()] * (parameters['ENCODER_SEQUENCE_LENGTH'] - len(news_encoded)))\n",
    "\n",
    "        if len(title_encoded) >= parameters['DECODER_SEQUENCE_LENGTH']:\n",
    "            data['decoder_targets'].append(title_encoded[:parameters['DECODER_SEQUENCE_LENGTH']])\n",
    "        else:\n",
    "            data['decoder_targets'].append(title_encoded + [sp.pad_id()] * (parameters['DECODER_SEQUENCE_LENGTH'] - len(title_encoded)))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab889620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:50:05.398191Z",
     "iopub.status.busy": "2025-05-04T06:50:05.397955Z",
     "iopub.status.idle": "2025-05-04T06:50:05.823346Z",
     "shell.execute_reply": "2025-05-04T06:50:05.822628Z"
    },
    "papermill": {
     "duration": 0.433304,
     "end_time": "2025-05-04T06:50:05.824951",
     "exception": false,
     "start_time": "2025-05-04T06:50:05.391647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=dataset_files, streaming=True)\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "eval_dataset = dataset[\"eval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52cfc505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:50:05.837863Z",
     "iopub.status.busy": "2025-05-04T06:50:05.837611Z",
     "iopub.status.idle": "2025-05-04T06:50:05.841801Z",
     "shell.execute_reply": "2025-05-04T06:50:05.841140Z"
    },
    "papermill": {
     "duration": 0.01175,
     "end_time": "2025-05-04T06:50:05.842911",
     "exception": false,
     "start_time": "2025-05-04T06:50:05.831161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=parameters['BATCH_SIZE'], collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=parameters['BATCH_SIZE'], collate_fn=collate_fn)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=parameters['BATCH_SIZE'], collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5dd66e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:50:05.855101Z",
     "iopub.status.busy": "2025-05-04T06:50:05.854825Z",
     "iopub.status.idle": "2025-05-04T06:55:32.773576Z",
     "shell.execute_reply": "2025-05-04T06:55:32.771497Z"
    },
    "papermill": {
     "duration": 326.926996,
     "end_time": "2025-05-04T06:55:32.775679",
     "exception": false,
     "start_time": "2025-05-04T06:50:05.848683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_inputs = None\n",
    "train_targets = None\n",
    "for batch in train_dataloader:\n",
    "    if train_inputs is None:\n",
    "        train_inputs = batch['encoder_inputs']\n",
    "        train_targets = batch['decoder_targets']\n",
    "    else:\n",
    "        train_inputs = train_inputs + batch['encoder_inputs']\n",
    "        train_targets = train_targets + batch['decoder_targets']\n",
    "train_inputs = np.array(train_inputs)\n",
    "train_targets = np.array(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e21219d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:55:32.790141Z",
     "iopub.status.busy": "2025-05-04T06:55:32.789856Z",
     "iopub.status.idle": "2025-05-04T06:56:07.865519Z",
     "shell.execute_reply": "2025-05-04T06:56:07.864536Z"
    },
    "papermill": {
     "duration": 35.084666,
     "end_time": "2025-05-04T06:56:07.867235",
     "exception": false,
     "start_time": "2025-05-04T06:55:32.782569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_inputs = None\n",
    "test_targets = None\n",
    "for batch in test_dataloader:\n",
    "    if test_inputs is None:\n",
    "        test_inputs = batch['encoder_inputs']\n",
    "        test_targets = batch['decoder_targets']\n",
    "    else:\n",
    "        test_inputs = test_inputs + batch['encoder_inputs']\n",
    "        test_targets = test_targets + batch['decoder_targets']\n",
    "test_inputs = np.array(test_inputs)\n",
    "test_targets = np.array(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "070a3c09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:07.880460Z",
     "iopub.status.busy": "2025-05-04T06:56:07.880222Z",
     "iopub.status.idle": "2025-05-04T06:56:24.803423Z",
     "shell.execute_reply": "2025-05-04T06:56:24.802550Z"
    },
    "papermill": {
     "duration": 16.931565,
     "end_time": "2025-05-04T06:56:24.805162",
     "exception": false,
     "start_time": "2025-05-04T06:56:07.873597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_inputs = None\n",
    "eval_targets = None\n",
    "for batch in eval_dataloader:\n",
    "    if eval_inputs is None:\n",
    "        eval_inputs = batch['encoder_inputs']\n",
    "        eval_targets = batch['decoder_targets']\n",
    "    else:\n",
    "        eval_inputs = eval_inputs + batch['encoder_inputs']\n",
    "        eval_targets = eval_targets + batch['decoder_targets']\n",
    "eval_inputs = np.array(eval_inputs)\n",
    "eval_targets = np.array(eval_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0a5f271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:24.818506Z",
     "iopub.status.busy": "2025-05-04T06:56:24.818268Z",
     "iopub.status.idle": "2025-05-04T06:56:26.554790Z",
     "shell.execute_reply": "2025-05-04T06:56:26.554077Z"
    },
    "papermill": {
     "duration": 1.744651,
     "end_time": "2025-05-04T06:56:26.556351",
     "exception": false,
     "start_time": "2025-05-04T06:56:24.811700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices((train_inputs, train_targets)).batch(parameters[\"BATCH_SIZE\"], drop_remainder=False)\n",
    "test = tf.data.Dataset.from_tensor_slices((test_inputs, test_targets)).batch(parameters[\"BATCH_SIZE\"], drop_remainder=False)\n",
    "val = tf.data.Dataset.from_tensor_slices((eval_inputs, eval_targets)).batch(parameters[\"BATCH_SIZE\"], drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e711bed4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:26.569374Z",
     "iopub.status.busy": "2025-05-04T06:56:26.569102Z",
     "iopub.status.idle": "2025-05-04T06:56:26.575531Z",
     "shell.execute_reply": "2025-05-04T06:56:26.574594Z"
    },
    "papermill": {
     "duration": 0.014248,
     "end_time": "2025-05-04T06:56:26.576850",
     "exception": false,
     "start_time": "2025-05-04T06:56:26.562602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((260787, 256),\n",
       " (260787, 12),\n",
       " (30788, 256),\n",
       " (30788, 12),\n",
       " (15246, 256),\n",
       " (15246, 12))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape, train_targets.shape, test_inputs.shape, test_targets.shape, eval_inputs.shape, eval_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "148b3bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:26.589583Z",
     "iopub.status.busy": "2025-05-04T06:56:26.589339Z",
     "iopub.status.idle": "2025-05-04T06:56:26.598076Z",
     "shell.execute_reply": "2025-05-04T06:56:26.597297Z"
    },
    "papermill": {
     "duration": 0.016568,
     "end_time": "2025-05-04T06:56:26.599401",
     "exception": false,
     "start_time": "2025-05-04T06:56:26.582833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(BahdanauAttention, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    # def build(self, input_shape):\n",
    "        self.W = tf.keras.layers.Dense(self.units, use_bias=False)\n",
    "        self.U = tf.keras.layers.Dense(self.units, use_bias=False)\n",
    "        self.Wc = tf.keras.layers.Dense(self.units)\n",
    "        self.V = tf.keras.layers.Dense(1, use_bias=False)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        encoder_outputs, decoder_hidden_state = input_shape\n",
    "        self.W.build((decoder_hidden_state[0], 1, decoder_hidden_state[1]))\n",
    "        self.U.build(encoder_outputs)\n",
    "        self.Wc.build((encoder_outputs[0], encoder_outputs[1], 1, 1))\n",
    "        self.V.build(encoder_outputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        encoder_outputs, decoder_hidden_state = input_shape\n",
    "        return decoder_hidden_state, decoder_hidden_state, (decoder_hidden_state[0], decoder_hidden_state[1], 1, 1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        encoder_outputs, encoder_mask, decoder_hidden_state, coverage_vector = inputs  # Select the output for the current time step\n",
    "\n",
    "        score = tf.reduce_sum(self.V(tf.nn.tanh(self.W(tf.expand_dims(tf.expand_dims(decoder_hidden_state, 1), 1)) + self.U(tf.expand_dims(encoder_outputs, 2)) + self.Wc(coverage_vector))), (2, 3))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # attention_weights = tf.squeeze(attention_weights, 2) * encoder_mask\n",
    "        attention_weights = attention_weights * encoder_mask\n",
    "\n",
    "        for_renorm = tf.reduce_sum(attention_weights, 1)\n",
    "\n",
    "        attention_weights = attention_weights / tf.reshape(for_renorm, (-1, 1))\n",
    "\n",
    "        coverage_vector += tf.reshape(attention_weights, [tf.shape(encoder_outputs)[0], -1, 1, 1])\n",
    "\n",
    "        # Calculate the context vector\n",
    "        context_vector = tf.reduce_sum(tf.reshape(attention_weights, [tf.shape(encoder_outputs)[0], -1, 1, 1]) * tf.expand_dims(encoder_outputs, 2), (1, 2))\n",
    "        # print(context_vector, \"BEF\")\n",
    "        # context_vector = tf.reshape(context_vector, [-1, tf.shape(encoder_outputs)[-1]])\n",
    "        # print(context_vector, \"AFT\")\n",
    "        return context_vector, attention_weights, coverage_vector\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'units': self.units\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5a20c47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:26.612025Z",
     "iopub.status.busy": "2025-05-04T06:56:26.611756Z",
     "iopub.status.idle": "2025-05-04T06:56:26.619394Z",
     "shell.execute_reply": "2025-05-04T06:56:26.618190Z"
    },
    "papermill": {
     "duration": 0.015151,
     "end_time": "2025-05-04T06:56:26.620544",
     "exception": false,
     "start_time": "2025-05-04T06:56:26.605393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout_rate, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.encoder_embedding = Embedding(self.vocab_size, self.embedding_dim, mask_zero=True, name='News_Embedding')\n",
    "        self.encoder_lstm = Bidirectional(LSTM(self.hidden_dim, return_sequences=True, return_state=True, dropout=self.dropout_rate), name='Encoder_BiLSTM')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.encoder_embedding.build(input_shape)\n",
    "        lstm_input = self.encoder_embedding.compute_output_shape(input_shape)\n",
    "        self.encoder_lstm.build(lstm_input)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        lstm_input = self.encoder_embedding.compute_output_shape(input_shape)\n",
    "        out, hf, cf, hb, cb = self.encoder_lstm.compute_output_shape(lstm_input)\n",
    "        return out, out, (hf[0], hf[1]+hb[1]), (cf[0], cf[1]+cb[1]) \n",
    "    \n",
    "    def call(self, encoder_input, training=False):\n",
    "        encoder_embedding = self.encoder_embedding(encoder_input)\n",
    "\n",
    "        encoder_mask = tf.cast(self.encoder_embedding.compute_mask(encoder_input), tf.float32)\n",
    "        \n",
    "        encoder_output, state_h_fwd, state_c_fwd, state_h_bwd, state_c_bwd = self.encoder_lstm(encoder_embedding, training=training)\n",
    "        \n",
    "        state_h = tf.concat([state_h_fwd, state_h_bwd], -1)\n",
    "        state_c = tf.concat([state_c_fwd, state_c_bwd], -1)\n",
    "        \n",
    "        return encoder_output, encoder_mask, state_h, state_c\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'vocab_size': self.vocab_size,\n",
    "            'embedding_dim': self.embedding_dim,\n",
    "            'hidden_dim': self.hidden_dim,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84f6bab3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:26.632901Z",
     "iopub.status.busy": "2025-05-04T06:56:26.632658Z",
     "iopub.status.idle": "2025-05-04T06:56:26.641041Z",
     "shell.execute_reply": "2025-05-04T06:56:26.640241Z"
    },
    "papermill": {
     "duration": 0.015815,
     "end_time": "2025-05-04T06:56:26.642219",
     "exception": false,
     "start_time": "2025-05-04T06:56:26.626404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout_rate, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.decoder_embedding = Embedding(self.vocab_size, self.embedding_dim, mask_zero=True, name='Title_Embedding')\n",
    "        self.decoder_lstm = LSTM(self.hidden_dim, return_sequences=True, return_state=True, dropout=self.dropout_rate, name='Decoder_LSTM')\n",
    "        self.bahdanau_attention = BahdanauAttention(units=self.hidden_dim, name=\"Bahdanau_Attention\")  \n",
    "        self.decoder_dense = Dense(self.vocab_size, activation = 'softmax', name=\"Softmax_Layer\")\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        decoder_input, encoder_outputs = input_shape\n",
    "        self.decoder_embedding.build(decoder_input)\n",
    "        lstm_input = self.decoder_embedding.compute_output_shape(decoder_input)\n",
    "        self.decoder_lstm.build(lstm_input)\n",
    "        lstm_output, h, c = self.decoder_lstm.compute_output_shape(lstm_input)\n",
    "        self.bahdanau_attention.build((encoder_outputs, h))\n",
    "        cxt, attn, cvg = self.bahdanau_attention.compute_output_shape((encoder_outputs, h))\n",
    "        self.decoder_dense.build((cxt[0], cxt[1]+h[1]))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        decoder_input, encoder_outputs = input_shape\n",
    "        lstm_input = self.decoder_embedding.compute_output_shape(decoder_input)\n",
    "        lstm_output, h, c = self.decoder_lstm.compute_output_shape(lstm_input)\n",
    "        cxt, attn, cvg = self.bahdanau_attention.compute_output_shape((encoder_outputs, h))\n",
    "        dist = self.decoder_dense.compute_output_shape((cxt[0], cxt[1]+h[1]))\n",
    "        return dist, h, c, attn, cvg\n",
    "    \n",
    "    def call(self, decoder_input, encoder_output, encoder_mask, previous_states, coverage_vector, training=False):\n",
    "        \n",
    "        decoder_embedding = self.decoder_embedding(decoder_input)\n",
    "\n",
    "        decoder_output, state_h, state_c, = self.decoder_lstm(decoder_embedding, initial_state=previous_states, training=training)\n",
    "        context_vector, attention_weights, coverage_vector = self.bahdanau_attention([encoder_output, encoder_mask, state_h, coverage_vector])\n",
    "        final_decoder_output = self.decoder_dense(tf.concat([context_vector, state_h], -1))\n",
    "        \n",
    "        return final_decoder_output, state_h, state_c, attention_weights, coverage_vector\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'vocab_size': self.vocab_size,\n",
    "            'embedding_dim': self.embedding_dim,\n",
    "            'hidden_dim': self.hidden_dim,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0187a410",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:26.654414Z",
     "iopub.status.busy": "2025-05-04T06:56:26.654174Z",
     "iopub.status.idle": "2025-05-04T06:56:26.657043Z",
     "shell.execute_reply": "2025-05-04T06:56:26.656271Z"
    },
    "papermill": {
     "duration": 0.010357,
     "end_time": "2025-05-04T06:56:26.658360",
     "exception": false,
     "start_time": "2025-05-04T06:56:26.648003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# enc_in = tf.keras.random.randint((4, 4), 0, 9)\n",
    "\n",
    "# dec_in = tf.keras.random.randint((4, 1), 0, 3)\n",
    "# dec_t = tf.keras.random.randint((4, 1), 0, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b85eceea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:26.670650Z",
     "iopub.status.busy": "2025-05-04T06:56:26.670446Z",
     "iopub.status.idle": "2025-05-04T06:56:26.673332Z",
     "shell.execute_reply": "2025-05-04T06:56:26.672698Z"
    },
    "papermill": {
     "duration": 0.010205,
     "end_time": "2025-05-04T06:56:26.674442",
     "exception": false,
     "start_time": "2025-05-04T06:56:26.664237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vocab_size, embedding_dim, hidden_dim, dropout_rate, enc_seq_len, batch = 10, 50, 10, 0.1, 4, 4\n",
    "# # enc_in = tf.keras.random.randint((batch, enc_seq_len), 0, 9)\n",
    "# enc = Encoder(vocab_size, embedding_dim, hidden_dim, dropout_rate)\n",
    "# x, y, z, zz = enc(enc_in)\n",
    "\n",
    "# vocab_size, embedding_dim, hidden_dim, dropout_rate, dec_seq_len, batch = 10, 50, 20, 0.1, 7, 4\n",
    "# # dec_in = tf.keras.random.randint((batch, 1), 0, 3)\n",
    "# # dec_t = tf.keras.random.randint((batch, 1), 0, 9)\n",
    "# dec = Decoder(vocab_size, embedding_dim, hidden_dim, dropout_rate)\n",
    "# dec.build(((None,1), x.shape))\n",
    "# # print(dec.compute_output_shape(((None,1), x.shape)))\n",
    "# a, b, c, d, e = dec(dec_in, x, y, [z, zz], np.zeros((enc_in.shape[0], enc_in.shape[1], 1, 1)))\n",
    "# f, g, h, i, j = dec(tf.keras.random.randint((batch, 1), 0, 3), x, y, [b, c], e)\n",
    "# f, g, h, i, j = dec(tf.keras.random.randint((batch, 1), 0, 3), x, y, [g, h], j)\n",
    "# # dec_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba775600",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:26.686528Z",
     "iopub.status.busy": "2025-05-04T06:56:26.686329Z",
     "iopub.status.idle": "2025-05-04T06:56:26.690190Z",
     "shell.execute_reply": "2025-05-04T06:56:26.689545Z"
    },
    "papermill": {
     "duration": 0.01116,
     "end_time": "2025-05-04T06:56:26.691276",
     "exception": false,
     "start_time": "2025-05-04T06:56:26.680116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def sparse_categorical_and_coverage_loss(targets, output_dist, attn_wts, coverage, coverage_weight=1):\n",
    "    scce_loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=None)\n",
    "    step_scce_loss = scce_loss(targets, output_dist)\n",
    "    step_cov_loss = tf.reduce_sum(tf.minimum(attn_wts, coverage), 1)\n",
    "\n",
    "    return tf.expand_dims(step_scce_loss, 1), tf.expand_dims(step_cov_loss, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04bd7875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:26.703469Z",
     "iopub.status.busy": "2025-05-04T06:56:26.703258Z",
     "iopub.status.idle": "2025-05-04T06:56:26.706233Z",
     "shell.execute_reply": "2025-05-04T06:56:26.705467Z"
    },
    "papermill": {
     "duration": 0.010245,
     "end_time": "2025-05-04T06:56:26.707414",
     "exception": false,
     "start_time": "2025-05-04T06:56:26.697169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# s1, sc1 = sparse_categorical_and_coverage_loss(tf.keras.random.randint((4, 1), 0, 10), tf.keras.random.uniform((4, 10)), tf.keras.random.uniform((4, 10)), tf.keras.random.uniform((4, 10)))\n",
    "# s2, sc2 = sparse_categorical_and_coverage_loss(tf.keras.random.randint((4, 1), 0, 10), tf.keras.random.uniform((4, 10)), tf.keras.random.uniform((4, 10)), tf.keras.random.uniform((4, 10)))\n",
    "# s3, sc3 = sparse_categorical_and_coverage_loss(tf.keras.random.randint((4, 1), 0, 10), tf.keras.random.uniform((4, 10)), tf.keras.random.uniform((4, 10)), tf.keras.random.uniform((4, 10)))\n",
    "# s4, sc4 = sparse_categorical_and_coverage_loss(tf.keras.random.randint((4, 1), 0, 10), tf.keras.random.uniform((4, 10)), tf.keras.random.uniform((4, 10)), tf.keras.random.uniform((4, 10)))\n",
    "# loss = tf.concat([s1, s2, s3, s4], 1)\n",
    "# cov_loss = tf.concat([sc1, sc2, sc3, sc4], 1)\n",
    "# mask = tf.cast(tf.math.not_equal(tf.keras.random.randint((4, 4), 0, 9), 0), tf.float32)\n",
    "# print(tf.reduce_mean(tf.reduce_sum(loss*mask, 1) / tf.reduce_sum(mask, 1)))\n",
    "# print(tf.reduce_mean(tf.reduce_sum(cov_loss*mask, 1) / tf.reduce_sum(mask, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "180dfc72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:26.719695Z",
     "iopub.status.busy": "2025-05-04T06:56:26.719493Z",
     "iopub.status.idle": "2025-05-04T06:56:26.735906Z",
     "shell.execute_reply": "2025-05-04T06:56:26.735339Z"
    },
    "papermill": {
     "duration": 0.02378,
     "end_time": "2025-05-04T06:56:26.737162",
     "exception": false,
     "start_time": "2025-05-04T06:56:26.713382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class AttentiveSeq2Seq(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, sos_token_id, teacher_forcing_ratio=0.5, coverage_weight=1.0, **kwargs):\n",
    "        super(AttentiveSeq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # self.loss_fn = loss\n",
    "        self.sos_token_id = sos_token_id\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.coverage_weight = coverage_weight\n",
    "\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.coverage_tracker = tf.keras.metrics.Mean(name=\"coverage_loss\")\n",
    "        self.val_loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.val_coverage_tracker = tf.keras.metrics.Mean(name=\"coverage_loss\")\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        encoder_input, decoder_input = input_shape\n",
    "        self.encoder.build(encoder_input)\n",
    "        encoder_outputs = self.encoder.compute_output_shape(encoder_input)\n",
    "        self.decoder.build((decoder_input, encoder_outputs[0]))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        encoder_input, decoder_input = input_shape\n",
    "        encoder_outputs = self.encoder.compute_output_shape(encoder_input)\n",
    "        decoder_outputs = self.decoder.compute_output_shape((decoder_input, encoder_outputs))\n",
    "        return encoder_outputs, decoder_outputs\n",
    "    \n",
    "    def call(self):\n",
    "        \"\"\"\n",
    "        Decoder Inputs: <sos>.....\n",
    "        Target: .....<eos>\n",
    "        \"\"\"\n",
    "\n",
    "        return self.encoder, self.decoder\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, inputs):\n",
    "\n",
    "        encoder_inputs, targets = inputs\n",
    "        loss = 0.\n",
    "        cov_loss = 0.\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            batch_loss = None\n",
    "            batch_cov_loss = None\n",
    "            target_mask = tf.cast(tf.math.not_equal(targets, 0), tf.float32)\n",
    "            \n",
    "            coverage_vector_next_t = tf.zeros([tf.shape(encoder_inputs)[0], tf.shape(encoder_inputs)[1], 1, 1], dtype=tf.float32)\n",
    "            decoder_input = tf.fill([tf.shape(encoder_inputs)[0],], self.sos_token_id)\n",
    "\n",
    "            encoder_outputs, encoder_mask, hidden, cell = self.encoder(encoder_inputs, training=True)\n",
    "            \n",
    "            for t in range(targets.shape[1]):\n",
    "                final_dist, hidden, cell, attn_weights, coverage_vector = self.decoder(tf.expand_dims(decoder_input, 1), encoder_outputs, encoder_mask, [hidden, cell], coverage_vector_next_t, training=True)\n",
    "                decoder_input = targets[:, t] if random.random() < self.teacher_forcing_ratio else tf.argmax(final_dist, 1)  \n",
    "\n",
    "                step_loss, step_cov_loss = self.loss(targets[:,t], final_dist, attn_weights, tf.squeeze(tf.squeeze(coverage_vector_next_t, 3), 2), self.coverage_weight)\n",
    "\n",
    "                if batch_loss is None:\n",
    "                    batch_loss = step_loss\n",
    "                    batch_cov_loss = step_cov_loss\n",
    "                else:\n",
    "                    batch_loss =tf.concat([batch_loss, step_loss], 1)\n",
    "                    batch_cov_loss =tf.concat([batch_cov_loss, step_cov_loss], 1)\n",
    "        \n",
    "                coverage_vector_next_t = coverage_vector                \n",
    "\n",
    "            loss = tf.reduce_mean(tf.reduce_sum(batch_loss*target_mask, 1) / tf.reduce_sum(target_mask, 1))\n",
    "            cov_loss = tf.reduce_mean(tf.reduce_sum(batch_cov_loss*target_mask, 1) / tf.reduce_sum(target_mask, 1))\n",
    "    \n",
    "            loss = loss + self.coverage_weight * cov_loss\n",
    "\n",
    "        variables = self.encoder.trainable_variables + self.decoder.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.coverage_tracker.update_state(cov_loss)\n",
    "\n",
    "        return {'loss': self.loss_tracker.result(), 'coverage_loss': self.coverage_tracker.result()}    \n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, inputs):\n",
    "        encoder_inputs, targets = inputs\n",
    "\n",
    "        batch_loss = None\n",
    "        batch_cov_loss = None\n",
    "        \n",
    "        target_mask = tf.cast(tf.math.not_equal(targets, 0), tf.float32)\n",
    "        \n",
    "        coverage_vector_next_t = tf.zeros([tf.shape(encoder_inputs)[0], tf.shape(encoder_inputs)[1], 1, 1], dtype=tf.float32)\n",
    "        decoder_input = tf.fill([tf.shape(encoder_inputs)[0],], self.sos_token_id)\n",
    "\n",
    "        encoder_outputs, encoder_mask, hidden, cell = self.encoder(encoder_inputs, training=False)\n",
    "        \n",
    "        for t in range(targets.shape[1]):\n",
    "            final_dist, hidden, cell, attn_weights, coverage_vector = self.decoder(tf.expand_dims(decoder_input, 1), encoder_outputs, encoder_mask, [hidden, cell], coverage_vector_next_t, training=False)\n",
    "            decoder_input = tf.argmax(final_dist, 1)  \n",
    "\n",
    "            step_loss, step_cov_loss = self.loss(targets[:,t], final_dist, attn_weights, tf.squeeze(tf.squeeze(coverage_vector_next_t, 3), 2), self.coverage_weight)\n",
    "\n",
    "            if batch_loss is None:\n",
    "                batch_loss = step_loss\n",
    "                batch_cov_loss = step_cov_loss\n",
    "            else:\n",
    "                batch_loss =tf.concat([batch_loss, step_loss], 1)\n",
    "                batch_cov_loss =tf.concat([batch_cov_loss, step_cov_loss], 1)\n",
    "    \n",
    "            coverage_vector_next_t = coverage_vector                \n",
    "                    \n",
    "        loss = tf.reduce_mean(tf.reduce_sum(batch_loss*target_mask, 1) / tf.reduce_sum(target_mask, 1))\n",
    "        cov_loss = tf.reduce_mean(tf.reduce_sum(batch_cov_loss*target_mask, 1) / tf.reduce_sum(target_mask, 1))\n",
    "\n",
    "        final_loss = loss + self.coverage_weight * cov_loss\n",
    "\n",
    "        self.val_loss_tracker.update_state(final_loss)\n",
    "        self.val_coverage_tracker.update_state(cov_loss)\n",
    "\n",
    "        return {'loss': self.val_loss_tracker.result(), 'coverage_loss': self.val_coverage_tracker.result()}    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'encoder': self.encoder,\n",
    "            'decoder': self.decoder,\n",
    "            'sos_token_id': self.sos_token_id,\n",
    "            'teacher_forcing_ratio': self.teacher_forcing_ratio,\n",
    "            'coverage_weight': self.coverage_weight,\n",
    "            'loss_tracker': self.loss_tracker,\n",
    "            'coverage_tracker': self.coverage_tracker,\n",
    "            'val_loss_tracker': self.val_loss_tracker,\n",
    "            'val_coverage_tracker': self.val_coverage_tracker\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b47bb7f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:26.749748Z",
     "iopub.status.busy": "2025-05-04T06:56:26.749542Z",
     "iopub.status.idle": "2025-05-04T06:56:26.752509Z",
     "shell.execute_reply": "2025-05-04T06:56:26.751895Z"
    },
    "papermill": {
     "duration": 0.010487,
     "end_time": "2025-05-04T06:56:26.753689",
     "exception": false,
     "start_time": "2025-05-04T06:56:26.743202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13a2bce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:26.765941Z",
     "iopub.status.busy": "2025-05-04T06:56:26.765726Z",
     "iopub.status.idle": "2025-05-04T06:56:28.651439Z",
     "shell.execute_reply": "2025-05-04T06:56:28.650452Z"
    },
    "papermill": {
     "duration": 1.893592,
     "end_time": "2025-05-04T06:56:28.653178",
     "exception": false,
     "start_time": "2025-05-04T06:56:26.759586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(parameters['VOC_SIZE'], parameters['EMBEDDING_DIMENSION'], parameters['ENCODER_HIDDEN_DIM'], parameters['DROPOUT'])\n",
    "decoder = Decoder(parameters['VOC_SIZE'], parameters['EMBEDDING_DIMENSION'], parameters['DECODER_HIDDEN_DIM'], parameters['DROPOUT'])    \n",
    "model = AttentiveSeq2Seq(encoder, decoder,parameters['SOS_TOKEN_ID'])\n",
    "model.build(((None, parameters['ENCODER_SEQUENCE_LENGTH']), (None, parameters['DECODER_SEQUENCE_LENGTH'])))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=parameters['LEARNING_RATE'], weight_decay=parameters['L2_REG']), loss=sparse_categorical_and_coverage_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e50a6fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:28.666126Z",
     "iopub.status.busy": "2025-05-04T06:56:28.665823Z",
     "iopub.status.idle": "2025-05-04T06:56:28.680470Z",
     "shell.execute_reply": "2025-05-04T06:56:28.679638Z"
    },
    "papermill": {
     "duration": 0.022308,
     "end_time": "2025-05-04T06:56:28.681677",
     "exception": false,
     "start_time": "2025-05-04T06:56:28.659369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"attentive_seq2_seq\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"attentive_seq2_seq\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)                    │ ((<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,084,480</span> │\n",
       "│                                      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │                 │\n",
       "│                                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>))                │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)                    │ ((<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50000</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">18,000,400</span> │\n",
       "│                                      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │                 │\n",
       "│                                      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>))    │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder (\u001b[38;5;33mEncoder\u001b[0m)                    │ ((\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │       \u001b[38;5;34m5,084,480\u001b[0m │\n",
       "│                                      │ \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │                 │\n",
       "│                                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m))                │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder (\u001b[38;5;33mDecoder\u001b[0m)                    │ ((\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50000\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │      \u001b[38;5;34m18,000,400\u001b[0m │\n",
       "│                                      │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │                 │\n",
       "│                                      │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m))    │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,084,880</span> (88.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,084,880\u001b[0m (88.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,084,880</span> (88.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,084,880\u001b[0m (88.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aec9c85d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:28.695319Z",
     "iopub.status.busy": "2025-05-04T06:56:28.695063Z",
     "iopub.status.idle": "2025-05-04T06:56:28.698881Z",
     "shell.execute_reply": "2025-05-04T06:56:28.698113Z"
    },
    "papermill": {
     "duration": 0.011852,
     "end_time": "2025-05-04T06:56:28.700113",
     "exception": false,
     "start_time": "2025-05-04T06:56:28.688261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpk = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='/kaggle/working/best.weights.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    ")\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode=\"min\", patience=parameters['EARLY_STOPPING'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f913ed85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T06:56:28.713470Z",
     "iopub.status.busy": "2025-05-04T06:56:28.713255Z",
     "iopub.status.idle": "2025-05-04T14:21:37.414485Z",
     "shell.execute_reply": "2025-05-04T14:21:37.413534Z"
    },
    "papermill": {
     "duration": 26710.350909,
     "end_time": "2025-05-04T14:21:39.057455",
     "exception": false,
     "start_time": "2025-05-04T06:56:28.706546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'Bahdanau_Attention' (of type BahdanauAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1792s\u001b[0m 876ms/step - coverage_loss: 0.2387 - loss: 8.3596 - val_coverage_loss: 0.0115 - val_loss: 7.3359\n",
      "Epoch 2/16\n",
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1780s\u001b[0m 873ms/step - coverage_loss: 0.0148 - loss: 7.0556 - val_coverage_loss: 0.0219 - val_loss: 7.0232\n",
      "Epoch 3/16\n",
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1789s\u001b[0m 878ms/step - coverage_loss: 0.0126 - loss: 6.6009 - val_coverage_loss: 0.0283 - val_loss: 6.8730\n",
      "Epoch 4/16\n",
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1780s\u001b[0m 873ms/step - coverage_loss: 0.0438 - loss: 6.5153 - val_coverage_loss: 0.0055 - val_loss: 6.7170\n",
      "Epoch 5/16\n",
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1761s\u001b[0m 864ms/step - coverage_loss: 0.0079 - loss: 6.0776 - val_coverage_loss: 0.0059 - val_loss: 6.6057\n",
      "Epoch 6/16\n",
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1760s\u001b[0m 864ms/step - coverage_loss: 0.0062 - loss: 5.8668 - val_coverage_loss: 0.0062 - val_loss: 6.5145\n",
      "Epoch 7/16\n",
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1760s\u001b[0m 864ms/step - coverage_loss: 0.0162 - loss: 5.8407 - val_coverage_loss: 0.0131 - val_loss: 6.4955\n",
      "Epoch 8/16\n",
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1764s\u001b[0m 866ms/step - coverage_loss: 0.0118 - loss: 5.6061 - val_coverage_loss: 0.0081 - val_loss: 6.3973\n",
      "Epoch 9/16\n",
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1758s\u001b[0m 862ms/step - coverage_loss: 0.0079 - loss: 5.4279 - val_coverage_loss: 0.0104 - val_loss: 6.3798\n",
      "Epoch 10/16\n",
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1785s\u001b[0m 876ms/step - coverage_loss: 0.0077 - loss: 5.3076 - val_coverage_loss: 0.0123 - val_loss: 6.3241\n",
      "Epoch 11/16\n",
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1797s\u001b[0m 882ms/step - coverage_loss: 0.0087 - loss: 5.2330 - val_coverage_loss: 0.0077 - val_loss: 6.2568\n",
      "Epoch 12/16\n",
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1801s\u001b[0m 884ms/step - coverage_loss: 0.0074 - loss: 5.0792 - val_coverage_loss: 0.0082 - val_loss: 6.2267\n",
      "Epoch 13/16\n",
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1800s\u001b[0m 883ms/step - coverage_loss: 0.0110 - loss: 5.0532 - val_coverage_loss: 0.0266 - val_loss: 6.4191\n",
      "Epoch 14/16\n",
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1781s\u001b[0m 874ms/step - coverage_loss: 0.0386 - loss: 5.3911 - val_coverage_loss: 0.0318 - val_loss: 6.4131\n",
      "Epoch 15/16\n",
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1801s\u001b[0m 884ms/step - coverage_loss: 0.0341 - loss: 5.3000 - val_coverage_loss: 0.0314 - val_loss: 6.3279\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, epochs=parameters[\"EPOCHS\"], batch_size=parameters[\"BATCH_SIZE\"], validation_data=test, callbacks=[cpk, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3d5fe7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:21:42.302799Z",
     "iopub.status.busy": "2025-05-04T14:21:42.302497Z",
     "iopub.status.idle": "2025-05-04T14:21:43.036700Z",
     "shell.execute_reply": "2025-05-04T14:21:43.035998Z"
    },
    "papermill": {
     "duration": 2.384509,
     "end_time": "2025-05-04T14:21:43.038472",
     "exception": false,
     "start_time": "2025-05-04T14:21:40.653963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "model.save_weights('/kaggle/working/model.weights.h5')\n",
    "with open('/kaggle/working/model_history', 'wb') as file:\n",
    "    pickle.dump(history.history, file)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7043519,
     "sourceId": 11267959,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7043530,
     "sourceId": 11267972,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27135.501801,
   "end_time": "2025-05-04T14:21:57.244324",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-04T06:49:41.742523",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
