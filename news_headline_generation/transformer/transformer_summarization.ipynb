{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91c1299b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-05T06:10:32.053691Z",
     "iopub.status.busy": "2025-05-05T06:10:32.053408Z",
     "iopub.status.idle": "2025-05-05T06:10:48.498846Z",
     "shell.execute_reply": "2025-05-05T06:10:48.497890Z"
    },
    "papermill": {
     "duration": 16.45506,
     "end_time": "2025-05-05T06:10:48.500451",
     "exception": false,
     "start_time": "2025-05-05T06:10:32.045391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "import random\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Input, Dense, TimeDistributed, Embedding, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import pickle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ce9dc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:10:48.514819Z",
     "iopub.status.busy": "2025-05-05T06:10:48.514296Z",
     "iopub.status.idle": "2025-05-05T06:10:48.962897Z",
     "shell.execute_reply": "2025-05-05T06:10:48.961952Z"
    },
    "papermill": {
     "duration": 0.457023,
     "end_time": "2025-05-05T06:10:48.964330",
     "exception": false,
     "start_time": "2025-05-05T06:10:48.507307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "       tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1059ec18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:10:48.977968Z",
     "iopub.status.busy": "2025-05-05T06:10:48.977673Z",
     "iopub.status.idle": "2025-05-05T06:10:49.036570Z",
     "shell.execute_reply": "2025-05-05T06:10:49.035687Z"
    },
    "papermill": {
     "duration": 0.067181,
     "end_time": "2025-05-05T06:10:49.037979",
     "exception": false,
     "start_time": "2025-05-05T06:10:48.970798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"/kaggle/input/nepali-summarization-tokenizer/summarization_50000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dcbc309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:10:49.052231Z",
     "iopub.status.busy": "2025-05-05T06:10:49.051917Z",
     "iopub.status.idle": "2025-05-05T06:10:49.056768Z",
     "shell.execute_reply": "2025-05-05T06:10:49.055908Z"
    },
    "papermill": {
     "duration": 0.01317,
     "end_time": "2025-05-05T06:10:49.058136",
     "exception": false,
     "start_time": "2025-05-05T06:10:49.044966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'VOC_SIZE': 50_000,\n",
    "\n",
    "    'ENCODER_LAYERS': 6,\n",
    "    'DECODER_LAYERS': 6,\n",
    "\n",
    "    'ENCODER_SEQUENCE_LENGTH': 256,\n",
    "    'DECODER_SEQUENCE_LENGTH': 12,\n",
    "    \n",
    "    'EMBEDDING_DIMENSION': 256,\n",
    "    'ENCODER_ATTENTION_HEADS': 8,\n",
    "    'DECODER_ATTENTION_HEADS': 8,\n",
    "    'ENCODER_FFN_DIM': 4 * 512,\n",
    "    'DECODER_FFN_DIM': 4 * 512,\n",
    "    \n",
    "    'DROPOUT': 0.2,\n",
    "\n",
    "    'BATCH_SIZE': 64,\n",
    "    'EPOCHS': 20,\n",
    "    'EARLY_STOPPING': 4,\n",
    "    'L2_REG': 0.01,\n",
    "    \n",
    "    'LEARNING_RATE': 1e-4,\n",
    "\n",
    "    'LABEL_SMOOTHING': 0.1,\n",
    "    'TEACHER_FORCING_RATIO': 0.5,\n",
    "    'GRAD_CLIP': 1.0,\n",
    "\n",
    "    'PAD_TOKEN': '<pad>',\n",
    "    'UNK_TOKEN': '<unk>',\n",
    "    'SOS_TOKEN': '<s>',\n",
    "    'EOS_TOKEN': '</s>',\n",
    "\n",
    "    'PAD_TOKEN_ID': sp.pad_id(),\n",
    "    'UNK_TOKEN_ID': sp.unk_id(),\n",
    "    'SOS_TOKEN_ID': sp.bos_id(),\n",
    "    'EOS_TOKEN_ID': sp.eos_id(),\n",
    "\n",
    "    'COVERAGE_WEIGHT': 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c106bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:10:49.071912Z",
     "iopub.status.busy": "2025-05-05T06:10:49.071632Z",
     "iopub.status.idle": "2025-05-05T06:10:49.075211Z",
     "shell.execute_reply": "2025-05-05T06:10:49.074282Z"
    },
    "papermill": {
     "duration": 0.011947,
     "end_time": "2025-05-05T06:10:49.076595",
     "exception": false,
     "start_time": "2025-05-05T06:10:49.064648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_files = {\n",
    "    \"train\": \"/kaggle/input/nepali-summarization-set-cleaned/summarization_set_cleaned_train.csv\",\n",
    "    \"test\": \"/kaggle/input/nepali-summarization-set-cleaned/summarization_set_cleaned_test.csv\",\n",
    "    \"eval\": \"/kaggle/input/nepali-summarization-set-cleaned/summarization_set_cleaned_val.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5628be8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:10:49.090333Z",
     "iopub.status.busy": "2025-05-05T06:10:49.090080Z",
     "iopub.status.idle": "2025-05-05T06:10:49.096083Z",
     "shell.execute_reply": "2025-05-05T06:10:49.095275Z"
    },
    "papermill": {
     "duration": 0.014168,
     "end_time": "2025-05-05T06:10:49.097324",
     "exception": false,
     "start_time": "2025-05-05T06:10:49.083156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    data = {\n",
    "        'encoder_inputs': [],\n",
    "        'decoder_inputs': [],\n",
    "        'decoder_targets': [],\n",
    "    }\n",
    "\n",
    "    for row in batch:\n",
    "        news_encoded = sp.encode(row['news'])\n",
    "        title_encoded = sp.encode(row['title']) + [sp.eos_id()]\n",
    "        title_encoded_inp = [sp.bos_id()] + sp.encode(row['title'])\n",
    "\n",
    "        if len(news_encoded) >= parameters['ENCODER_SEQUENCE_LENGTH']:\n",
    "            data['encoder_inputs'].append(news_encoded[:parameters['ENCODER_SEQUENCE_LENGTH']])\n",
    "        else:\n",
    "            data['encoder_inputs'].append(news_encoded + [sp.pad_id()] * (parameters['ENCODER_SEQUENCE_LENGTH'] - len(news_encoded)))\n",
    "\n",
    "        if len(title_encoded) >= parameters['DECODER_SEQUENCE_LENGTH']:\n",
    "            data['decoder_targets'].append(title_encoded[:parameters['DECODER_SEQUENCE_LENGTH']])\n",
    "        else:\n",
    "            data['decoder_targets'].append(title_encoded + [sp.pad_id()] * (parameters['DECODER_SEQUENCE_LENGTH'] - len(title_encoded)))\n",
    "            \n",
    "        if len(title_encoded_inp) >= parameters['DECODER_SEQUENCE_LENGTH']:\n",
    "            data['decoder_inputs'].append(title_encoded_inp[:parameters['DECODER_SEQUENCE_LENGTH']])\n",
    "        else:\n",
    "            data['decoder_inputs'].append(title_encoded_inp + [sp.pad_id()] * (parameters['DECODER_SEQUENCE_LENGTH'] - len(title_encoded_inp)))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc94aa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:10:49.110658Z",
     "iopub.status.busy": "2025-05-05T06:10:49.110425Z",
     "iopub.status.idle": "2025-05-05T06:10:49.877489Z",
     "shell.execute_reply": "2025-05-05T06:10:49.876549Z"
    },
    "papermill": {
     "duration": 0.775499,
     "end_time": "2025-05-05T06:10:49.879163",
     "exception": false,
     "start_time": "2025-05-05T06:10:49.103664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=dataset_files, streaming=True)\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "eval_dataset = dataset[\"eval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2360b05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:10:49.893205Z",
     "iopub.status.busy": "2025-05-05T06:10:49.892829Z",
     "iopub.status.idle": "2025-05-05T06:10:49.897119Z",
     "shell.execute_reply": "2025-05-05T06:10:49.896307Z"
    },
    "papermill": {
     "duration": 0.012563,
     "end_time": "2025-05-05T06:10:49.898394",
     "exception": false,
     "start_time": "2025-05-05T06:10:49.885831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=parameters['BATCH_SIZE'], collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=parameters['BATCH_SIZE'], collate_fn=collate_fn)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=parameters['BATCH_SIZE'], collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcf5827d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:10:49.912075Z",
     "iopub.status.busy": "2025-05-05T06:10:49.911762Z",
     "iopub.status.idle": "2025-05-05T06:10:51.479322Z",
     "shell.execute_reply": "2025-05-05T06:10:51.478576Z"
    },
    "papermill": {
     "duration": 1.576142,
     "end_time": "2025-05-05T06:10:51.480909",
     "exception": false,
     "start_time": "2025-05-05T06:10:49.904767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv('/kaggle/input/nepali-summarization-set-cleaned/summarization_set_cleaned_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d96e198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:10:51.495391Z",
     "iopub.status.busy": "2025-05-05T06:10:51.495096Z",
     "iopub.status.idle": "2025-05-05T06:17:33.449842Z",
     "shell.execute_reply": "2025-05-05T06:17:33.447420Z"
    },
    "papermill": {
     "duration": 401.964671,
     "end_time": "2025-05-05T06:17:33.452690",
     "exception": false,
     "start_time": "2025-05-05T06:10:51.488019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_inputs = None\n",
    "train_targets = None\n",
    "train_dec_inputs = None\n",
    "for batch in train_dataloader:\n",
    "    if train_inputs is None:\n",
    "        train_inputs = batch['encoder_inputs']\n",
    "        train_targets = batch['decoder_targets']\n",
    "        train_decoder_inputs = batch['decoder_inputs']\n",
    "    else:\n",
    "        train_inputs = train_inputs + batch['encoder_inputs']\n",
    "        train_targets = train_targets + batch['decoder_targets']\n",
    "        train_decoder_inputs = train_decoder_inputs + batch['decoder_inputs']\n",
    "train_inputs = np.array(train_inputs)\n",
    "train_targets = np.array(train_targets)\n",
    "train_decoder_inputs = np.array(train_decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ebce41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:17:33.469017Z",
     "iopub.status.busy": "2025-05-05T06:17:33.468544Z",
     "iopub.status.idle": "2025-05-05T06:18:12.638779Z",
     "shell.execute_reply": "2025-05-05T06:18:12.637770Z"
    },
    "papermill": {
     "duration": 39.180648,
     "end_time": "2025-05-05T06:18:12.640731",
     "exception": false,
     "start_time": "2025-05-05T06:17:33.460083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_inputs = None\n",
    "test_targets = None\n",
    "test_decoder_inputs = None\n",
    "for batch in test_dataloader:\n",
    "    if test_inputs is None:\n",
    "        test_inputs = batch['encoder_inputs']\n",
    "        test_targets = batch['decoder_targets']\n",
    "        test_decoder_inputs = batch['decoder_inputs']\n",
    "    else:\n",
    "        test_inputs = test_inputs + batch['encoder_inputs']\n",
    "        test_targets = test_targets + batch['decoder_targets']\n",
    "        test_decoder_inputs = test_decoder_inputs + batch['decoder_inputs']\n",
    "test_inputs = np.array(test_inputs)\n",
    "test_targets = np.array(test_targets)\n",
    "test_decoder_inputs = np.array(test_decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6025a1b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:12.655847Z",
     "iopub.status.busy": "2025-05-05T06:18:12.655548Z",
     "iopub.status.idle": "2025-05-05T06:18:31.092180Z",
     "shell.execute_reply": "2025-05-05T06:18:31.090851Z"
    },
    "papermill": {
     "duration": 18.445938,
     "end_time": "2025-05-05T06:18:31.093823",
     "exception": false,
     "start_time": "2025-05-05T06:18:12.647885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_inputs = None\n",
    "eval_targets = None\n",
    "eval_decoder_inputs = None\n",
    "for batch in eval_dataloader:\n",
    "    if eval_inputs is None:\n",
    "        eval_inputs = batch['encoder_inputs']\n",
    "        eval_targets = batch['decoder_targets']\n",
    "        eval_decoder_inputs = batch['decoder_inputs']\n",
    "    else:\n",
    "        eval_inputs = eval_inputs + batch['encoder_inputs']\n",
    "        eval_targets = eval_targets + batch['decoder_targets']\n",
    "        eval_decoder_inputs = eval_decoder_inputs + batch['decoder_inputs']\n",
    "eval_inputs = np.array(eval_inputs)\n",
    "eval_targets = np.array(eval_targets)\n",
    "eval_decoder_inputs = np.array(eval_decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f688ba3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:31.108167Z",
     "iopub.status.busy": "2025-05-05T06:18:31.107863Z",
     "iopub.status.idle": "2025-05-05T06:18:32.811607Z",
     "shell.execute_reply": "2025-05-05T06:18:32.810081Z"
    },
    "papermill": {
     "duration": 1.712449,
     "end_time": "2025-05-05T06:18:32.813268",
     "exception": false,
     "start_time": "2025-05-05T06:18:31.100819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices((train_inputs, train_decoder_inputs, train_targets)).batch(parameters[\"BATCH_SIZE\"], drop_remainder=False)\n",
    "test = tf.data.Dataset.from_tensor_slices((test_inputs, test_decoder_inputs, test_targets)).batch(parameters[\"BATCH_SIZE\"], drop_remainder=False)\n",
    "val = tf.data.Dataset.from_tensor_slices((eval_inputs, eval_decoder_inputs, eval_targets)).batch(parameters[\"BATCH_SIZE\"], drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbb12d69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:32.827897Z",
     "iopub.status.busy": "2025-05-05T06:18:32.827613Z",
     "iopub.status.idle": "2025-05-05T06:18:32.834856Z",
     "shell.execute_reply": "2025-05-05T06:18:32.833847Z"
    },
    "papermill": {
     "duration": 0.015713,
     "end_time": "2025-05-05T06:18:32.836161",
     "exception": false,
     "start_time": "2025-05-05T06:18:32.820448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Embeddings(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model: int, seq_len: int, voc_size: int, dropout_rate: float = 0.1, **kwargs):\n",
    "        super(Embeddings, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.voc_size = voc_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.input_emb = tf.keras.layers.Embedding(self.voc_size, self.d_model, name='Sequence_Embedding')\n",
    "        self.positional_emb = tf.keras.layers.Embedding(self.seq_len, self.d_model, name='Positional_Embedding')\n",
    "        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_emb.build(input_shape)\n",
    "        self.positional_emb.build(input_shape)\n",
    "        output_shape = self.input_emb.compute_output_shape(input_shape)\n",
    "        self.dropout.build(output_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.input_emb.compute_output_shape(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # inputs -> (batch, seq_len)\n",
    "        positions = tf.repeat(tf.expand_dims(tf.range(tf.shape(inputs)[1]), 0), [tf.shape(inputs)[0]], axis=0) # (batch, seq_len) \n",
    "        inp_emb = self.input_emb(inputs) # (batch, seq_len, d_model)\n",
    "        pos_emb = self.positional_emb(positions) # (batch, seq_len, d_model)\n",
    "\n",
    "        return self.dropout(inp_emb + pos_emb, training=training) # (batch, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f7d8245",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:32.849806Z",
     "iopub.status.busy": "2025-05-05T06:18:32.849548Z",
     "iopub.status.idle": "2025-05-05T06:18:32.860307Z",
     "shell.execute_reply": "2025-05-05T06:18:32.859332Z"
    },
    "papermill": {
     "duration": 0.018943,
     "end_time": "2025-05-05T06:18:32.861570",
     "exception": false,
     "start_time": "2025-05-05T06:18:32.842627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model: int, h: int, dropout_rate: float = 0.1, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        assert d_model % h == 0\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        self.d_k = self.d_model // self.h\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.w_q = tf.keras.layers.Dense(self.d_model) \n",
    "        self.w_k = tf.keras.layers.Dense(self.d_model) \n",
    "        self.w_v = tf.keras.layers.Dense(self.d_model) \n",
    "        self.w_o = tf.keras.layers.Dense(self.d_model)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        q, k, v = input_shape\n",
    "        self.w_q.build(q)\n",
    "        self.w_k.build(k)\n",
    "        self.w_v.build(v)\n",
    "        self.w_o.build(q)\n",
    "        self.dropout.build(q)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        q, k, v = input_shape\n",
    "        return self.dropout.compute_output_shape(q), (q[0], self.h, q[1], k[1]) \n",
    "        \n",
    "    def scaled_dot_product_attention(self, q, k, v, mask=None):\n",
    "        attn_score = q @ tf.transpose(k, perm=[0,1,3,2]) / tf.sqrt(tf.cast(k.shape[-1], dtype=tf.float32))\n",
    "        if mask is not None:\n",
    "            # attn_score += (mask * -1e9)\n",
    "            attn_score = tf.where(mask==0, -1e9, attn_score) # Set very small values where mask = 0\n",
    "            \n",
    "        attn_wts = tf.nn.softmax(attn_score, -1) # (batch, h, seq_len, seq_len) seq_len*seq_len because self attention\n",
    "        outputs = attn_wts @ v # (batch, h, seq_len, d_k)\n",
    "        return outputs, attn_wts\n",
    "\n",
    "    def call(self, q, k, v, mask=None, training=False):\n",
    "        q = self.w_q(q) # (batch, seq_len, d_model)\n",
    "        k = self.w_k(k)\n",
    "        v = self.w_v(v)\n",
    "\n",
    "        # Convert (batch, seq_len, d_model) to (batch, h, seq_len, d_k)\n",
    "        # Split d_model into h*d_k and then transpose the 2nd and 3rd dimension\n",
    "        q = tf.transpose(tf.reshape(q, [tf.shape(q)[0], tf.shape(q)[1], self.h, self.d_k]), perm=[0,2,1,3])\n",
    "        k = tf.transpose(tf.reshape(k, [tf.shape(k)[0], tf.shape(k)[1], self.h, self.d_k]), perm=[0,2,1,3])\n",
    "        v = tf.transpose(tf.reshape(v, [tf.shape(v)[0], tf.shape(v)[1], self.h, self.d_k]), perm=[0,2,1,3])\n",
    "\n",
    "        outputs, attn_weights = self.scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        # First Convert (batch, h, seq_len, d_k) to (batch, seq_len, d_model)\n",
    "        # Reverse the above operations\n",
    "        # Run through Dense to get (batch, seq_len, d_model) \n",
    "        outputs = self.w_o(tf.reshape(tf.transpose(outputs, perm=[0,2,1,3]), [tf.shape(outputs)[0], tf.shape(outputs)[2], self.d_model]))\n",
    "\n",
    "        return self.dropout(outputs, training=training), attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "107f8a85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:32.875386Z",
     "iopub.status.busy": "2025-05-05T06:18:32.875108Z",
     "iopub.status.idle": "2025-05-05T06:18:32.878705Z",
     "shell.execute_reply": "2025-05-05T06:18:32.877872Z"
    },
    "papermill": {
     "duration": 0.011822,
     "end_time": "2025-05-05T06:18:32.879988",
     "exception": false,
     "start_time": "2025-05-05T06:18:32.868166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# atn = MultiHeadAttention(d_model=100, h=2)\n",
    "# enc_emb = tf.keras.random.uniform((4, 20, 100))\n",
    "# dec_emb = tf.keras.random.uniform((4, 10, 100))\n",
    "# atn.build([(dec_emb.shape), (enc_emb.shape), (enc_emb.shape)])\n",
    "# x, y = atn(dec_emb, enc_emb, enc_emb)\n",
    "# print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3e1cf37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:32.893574Z",
     "iopub.status.busy": "2025-05-05T06:18:32.893324Z",
     "iopub.status.idle": "2025-05-05T06:18:32.898459Z",
     "shell.execute_reply": "2025-05-05T06:18:32.897343Z"
    },
    "papermill": {
     "duration": 0.013271,
     "end_time": "2025-05-05T06:18:32.899724",
     "exception": false,
     "start_time": "2025-05-05T06:18:32.886453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class AddAndNorm(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AddAndNorm, self).__init__(**kwargs)\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.layer_norm.build(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.layer_norm.compute_output_shape(input_shape)\n",
    "        \n",
    "    def call(self, skip_conn, output):\n",
    "        return self.layer_norm(skip_conn + output) # (batch, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efc25f27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:32.913549Z",
     "iopub.status.busy": "2025-05-05T06:18:32.913296Z",
     "iopub.status.idle": "2025-05-05T06:18:32.919131Z",
     "shell.execute_reply": "2025-05-05T06:18:32.918507Z"
    },
    "papermill": {
     "duration": 0.01415,
     "end_time": "2025-05-05T06:18:32.920406",
     "exception": false,
     "start_time": "2025-05-05T06:18:32.906256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class PositionwiseFeedForwardNetwork(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout_rate: float = 0.1, **kwargs):\n",
    "        super(PositionwiseFeedForwardNetwork, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.inner = tf.keras.layers.Dense(self.d_ff, activation='relu')\n",
    "        self.outer = tf.keras.layers.Dense(self.d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.inner.build(input_shape)\n",
    "        output = self.inner.compute_output_shape(input_shape)\n",
    "        self.outer.build(output)\n",
    "        self.dropout.build(self.outer.compute_output_shape(output))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.outer.compute_output_shape(self.inner.compute_output_shape(input_shape))\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.inner(inputs) # (batch, seq_len, d_ff)\n",
    "        x = self.outer(x) # (batch, seq_len, d_model)\n",
    "        return self.dropout(x, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7df20b38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:32.934148Z",
     "iopub.status.busy": "2025-05-05T06:18:32.933879Z",
     "iopub.status.idle": "2025-05-05T06:18:32.940198Z",
     "shell.execute_reply": "2025-05-05T06:18:32.939397Z"
    },
    "papermill": {
     "duration": 0.014312,
     "end_time": "2025-05-05T06:18:32.941479",
     "exception": false,
     "start_time": "2025-05-05T06:18:32.927167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class EncoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model: int, h:int, d_ff: int, dropout_rate: float = 0.1, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.mhsa = MultiHeadAttention(self.d_model, self.h, self.dropout_rate)\n",
    "        self.add_norm1 = AddAndNorm()\n",
    "        self.pffn = PositionwiseFeedForwardNetwork(self.d_model, self.d_ff, self.dropout_rate)\n",
    "        self.add_norm2 = AddAndNorm()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mhsa.build([input_shape, input_shape, input_shape])\n",
    "        self.add_norm1.build(input_shape)\n",
    "        self.pffn.build(input_shape)\n",
    "        self.add_norm2.build(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.mhsa.compute_output_shape([input_shape, input_shape, input_shape])\n",
    "\n",
    "    def call(self, inputs, mask=None, training=False):\n",
    "        mhsa_outputs, attn_weights = self.mhsa(inputs, inputs, inputs, mask, training=training)\n",
    "        x = self.add_norm1(inputs, mhsa_outputs)\n",
    "        pffn_outputs = self.pffn(x, training=training)\n",
    "        x = self.add_norm2(x, pffn_outputs)\n",
    "        \n",
    "        return x, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1dc903a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:32.955020Z",
     "iopub.status.busy": "2025-05-05T06:18:32.954778Z",
     "iopub.status.idle": "2025-05-05T06:18:32.961270Z",
     "shell.execute_reply": "2025-05-05T06:18:32.960405Z"
    },
    "papermill": {
     "duration": 0.014469,
     "end_time": "2025-05-05T06:18:32.962405",
     "exception": false,
     "start_time": "2025-05-05T06:18:32.947936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, N: int, d_model: int, seq_len: int, voc_size: int, h:int, d_ff: int, dropout_rate: float = 0.1, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        assert N > 0\n",
    "        self.N = N\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.voc_size = voc_size\n",
    "        self.h = h\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.embedding = Embeddings(self.d_model, self.seq_len, self.voc_size, self.dropout_rate)\n",
    "        self.enc_layers = [EncoderBlock(self.d_model, self.h, self.d_ff, self.dropout_rate) for _ in range(self.N)]\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embedding.build(input_shape)\n",
    "        output = self.embedding.compute_output_shape(input_shape)\n",
    "        for encoder in self.enc_layers:\n",
    "            encoder.build(output)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.enc_layers[0].compute_output_shape(self.embedding.compute_output_shape(input_shape))\n",
    "\n",
    "    def call(self, inputs, mask=None, training=False):\n",
    "        attn_weights = None\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        for encoder in self.enc_layers:\n",
    "            x, attn_weights = encoder(x, mask=mask, training=training) \n",
    "        return x, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "150ac011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:32.975796Z",
     "iopub.status.busy": "2025-05-05T06:18:32.975564Z",
     "iopub.status.idle": "2025-05-05T06:18:32.982654Z",
     "shell.execute_reply": "2025-05-05T06:18:32.981988Z"
    },
    "papermill": {
     "duration": 0.015159,
     "end_time": "2025-05-05T06:18:32.983900",
     "exception": false,
     "start_time": "2025-05-05T06:18:32.968741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DecoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model: int, h:int, d_ff: int, dropout_rate: float = 0.1, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.mhsa = MultiHeadAttention(self.d_model, self.h, self.dropout_rate)\n",
    "        self.add_norm1 = AddAndNorm()\n",
    "        self.mhca = MultiHeadAttention(self.d_model, self.h, self.dropout_rate)\n",
    "        self.add_norm2 = AddAndNorm()\n",
    "        self.pffn = PositionwiseFeedForwardNetwork(self.d_model, self.d_ff, self.dropout_rate)\n",
    "        self.add_norm3 = AddAndNorm()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dec_input_shape, enc_output_shape = input_shape\n",
    "        self.mhsa.build([dec_input_shape, dec_input_shape, dec_input_shape])\n",
    "        self.add_norm1.build(dec_input_shape)\n",
    "        self.mhca.build([dec_input_shape, enc_output_shape, enc_output_shape])\n",
    "        self.add_norm2.build(dec_input_shape)\n",
    "        self.pffn.build(dec_input_shape)\n",
    "        self.add_norm3.build(dec_input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        dec_input_shape, enc_output_shape = input_shape\n",
    "        return self.mhca.compute_output_shape([dec_input_shape, enc_output_shape, enc_output_shape])\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, decoder_mask=None, encoder_mask=None, training=False):\n",
    "        mhsa_outputs, _ = self.mhsa(inputs, inputs, inputs, mask=decoder_mask, training=training)\n",
    "        x = self.add_norm1(inputs, mhsa_outputs)\n",
    "        mhca_outputs, attn_weights = self.mhca(x, encoder_outputs, encoder_outputs, mask=encoder_mask, training=training)\n",
    "        x = self.add_norm2(x, mhca_outputs)\n",
    "        pffn_outputs = self.pffn(x, training=training)\n",
    "        x = self.add_norm3(x, pffn_outputs)\n",
    "\n",
    "        return x, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9b23ddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:32.997546Z",
     "iopub.status.busy": "2025-05-05T06:18:32.997311Z",
     "iopub.status.idle": "2025-05-05T06:18:33.003820Z",
     "shell.execute_reply": "2025-05-05T06:18:33.003187Z"
    },
    "papermill": {
     "duration": 0.014705,
     "end_time": "2025-05-05T06:18:33.005191",
     "exception": false,
     "start_time": "2025-05-05T06:18:32.990486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, N: int, d_model: int, seq_len: int, voc_size: int, h:int, d_ff: int, dropout_rate: float = 0.1, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        assert N > 0\n",
    "        self.N = N\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.voc_size = voc_size\n",
    "        self.h = h\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.embedding = Embeddings(self.d_model, self.seq_len, self.voc_size, self.dropout_rate)\n",
    "        self.dec_layers = [DecoderBlock(self.d_model, self.h, self.d_ff, self.dropout_rate) for _ in range(self.N)]\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dec_input_shape, enc_output_shape = input_shape\n",
    "        self.embedding.build(dec_input_shape)\n",
    "        output = self.embedding.compute_output_shape(dec_input_shape)\n",
    "        for decoder in self.dec_layers:\n",
    "            decoder.build([output, enc_output_shape])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        dec_input_shape, enc_output_shape = input_shape\n",
    "        return self.dec_layers[0].compute_output_shape([self.embedding.compute_output_shape(dec_input_shape), enc_output_shape])\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, decoder_mask=None, encoder_mask=None, training=False):\n",
    "        attn_weights = None\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        for decoder in self.dec_layers:\n",
    "            x, attn_weights = decoder(x, encoder_outputs, decoder_mask=decoder_mask, encoder_mask=encoder_mask, training=training) \n",
    "        return x, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14a97a41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:33.018865Z",
     "iopub.status.busy": "2025-05-05T06:18:33.018615Z",
     "iopub.status.idle": "2025-05-05T06:18:33.026660Z",
     "shell.execute_reply": "2025-05-05T06:18:33.026079Z"
    },
    "papermill": {
     "duration": 0.016217,
     "end_time": "2025-05-05T06:18:33.027846",
     "exception": false,
     "start_time": "2025-05-05T06:18:33.011629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Transformer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self, \n",
    "        encoder_layers: int, \n",
    "        decoder_layers: int,\n",
    "        d_model: int, \n",
    "        encoder_seq_len: int, \n",
    "        decoder_seq_len: int, \n",
    "        encoder_voc_size: int, \n",
    "        decoder_voc_size: int, \n",
    "        encoder_attention_heads: int, \n",
    "        decoder_attention_heads: int, \n",
    "        encoder_ffn_dim: int, \n",
    "        decoder_ffn_dim: int, \n",
    "        dropout: float = 0.1, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super(Transformer, self).__init__(**kwargs)\n",
    "        \n",
    "        self.encoder_layers = encoder_layers\n",
    "        self.decoder_layers = decoder_layers\n",
    "        assert self.encoder_layers > 0 and self.decoder_layers > 0, \"Encoder and Decoder must have atleast 1 layer\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.encoder_seq_len = encoder_seq_len\n",
    "        self.decoder_seq_len = decoder_seq_len\n",
    "        self.encoder_voc_size = encoder_voc_size\n",
    "        self.decoder_voc_size = decoder_voc_size\n",
    "        self.encoder_attention_heads = encoder_attention_heads\n",
    "        self.decoder_attention_heads = decoder_attention_heads\n",
    "        self.encoder_ffn_dim = encoder_ffn_dim\n",
    "        self.decoder_ffn_dim = decoder_ffn_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.encoder = Encoder(self.encoder_layers, self.d_model, self.encoder_seq_len, self.encoder_voc_size, self.encoder_attention_heads, self.encoder_ffn_dim, self.dropout)\n",
    "        self.decoder = Decoder(self.decoder_layers, self.d_model, self.decoder_seq_len, self.decoder_voc_size, self.decoder_attention_heads, self.decoder_ffn_dim, self.dropout)\n",
    "        self.projection = tf.keras.layers.Dense(decoder_voc_size)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        enc_input_shape, dec_input_shape = input_shape\n",
    "        self.encoder.build(enc_input_shape)\n",
    "        enc_output, _ = self.encoder.compute_output_shape(enc_input_shape)\n",
    "        self.decoder.build([dec_input_shape, enc_output])\n",
    "        dec_output, _ = self.decoder.compute_output_shape([dec_input_shape, enc_output])\n",
    "        self.projection.build(dec_output)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        enc_input_shape, dec_input_shape = input_shape\n",
    "        enc_output, enc_attn = self.encoder.compute_output_shape(enc_input_shape)\n",
    "        dec_output, dec_attn = self.decoder.compute_output_shape([dec_input_shape, enc_output])\n",
    "        return self.projection.compute_output_shape(dec_output), enc_attn, dec_attn\n",
    "\n",
    "    def call(self, encoder_inputs, decoder_inputs, encoder_mask=None, decoder_mask=None, training=False):\n",
    "        enc_outputs, enc_attn_wts = self.encoder(encoder_inputs, mask=encoder_mask, training=training)\n",
    "        dec_outputs, dec_attn_wts = self.decoder(decoder_inputs, enc_outputs, encoder_mask=encoder_mask, decoder_mask=decoder_mask, training=training)\n",
    "        logits = self.projection(dec_outputs)\n",
    "\n",
    "        return logits, enc_attn_wts, dec_attn_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f25390f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:33.041695Z",
     "iopub.status.busy": "2025-05-05T06:18:33.041458Z",
     "iopub.status.idle": "2025-05-05T06:18:33.044233Z",
     "shell.execute_reply": "2025-05-05T06:18:33.043621Z"
    },
    "papermill": {
     "duration": 0.011225,
     "end_time": "2025-05-05T06:18:33.045498",
     "exception": false,
     "start_time": "2025-05-05T06:18:33.034273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch, enc_layer, dec_layer, d_model = 2, 2, 2, 15\n",
    "# enc_seq_len, dec_seq_len, enc_voc_size, dec_voc_size = 13, 9, 70, 35\n",
    "# enc_attn_heads, dec_attn_heads = 5, 5\n",
    "# enc_ffn, dec_ffn = 16, 16\n",
    "# tformer = Transformer(enc_layer, dec_layer, d_model, enc_seq_len, dec_seq_len, enc_voc_size, dec_voc_size, enc_attn_heads, dec_attn_heads, enc_ffn, dec_ffn)\n",
    "# enc_inp = tf.keras.random.randint((batch, enc_seq_len), 0, enc_voc_size)\n",
    "# dec_inp = tf.keras.random.randint((batch, dec_seq_len), 0, dec_voc_size)\n",
    "# tformer.build([enc_inp.shape, dec_inp.shape])\n",
    "# res, enc_attn, dec_attn = tformer(enc_inp, dec_inp)\n",
    "# print(res.shape, enc_attn.shape, dec_attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aca52559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:33.058959Z",
     "iopub.status.busy": "2025-05-05T06:18:33.058724Z",
     "iopub.status.idle": "2025-05-05T06:18:33.063249Z",
     "shell.execute_reply": "2025-05-05T06:18:33.062566Z"
    },
    "papermill": {
     "duration": 0.012512,
     "end_time": "2025-05-05T06:18:33.064428",
     "exception": false,
     "start_time": "2025-05-05T06:18:33.051916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def cross_entropy_loss(targets, output_dist, mask=None, label_smoothing=0.1):\n",
    "    targets = tf.keras.utils.to_categorical(targets, num_classes=output_dist.shape[-1])\n",
    "    scce_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction=None, label_smoothing=label_smoothing)\n",
    "    step_scce_loss = scce_loss(targets, output_dist)\n",
    "    if mask is not None:\n",
    "        step_scce_loss = tf.reduce_mean(tf.reduce_sum(step_scce_loss*mask, 1) / tf.reduce_sum(mask, 1))\n",
    "    return step_scce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6686b584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:33.078381Z",
     "iopub.status.busy": "2025-05-05T06:18:33.078140Z",
     "iopub.status.idle": "2025-05-05T06:18:33.088878Z",
     "shell.execute_reply": "2025-05-05T06:18:33.088232Z"
    },
    "papermill": {
     "duration": 0.019145,
     "end_time": "2025-05-05T06:18:33.090106",
     "exception": false,
     "start_time": "2025-05-05T06:18:33.070961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class TransformerTrainer(tf.keras.Model):\n",
    "    def __init__(self, transformer: Transformer, label_smoothing: float = 0.1, **kwargs):\n",
    "        super(TransformerTrainer, self).__init__(**kwargs)\n",
    "        self.transformer = transformer\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.val_loss_tracker = tf.keras.metrics.Mean(name=\"val_loss\")\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        enc_input, dec_input, dec_output = input_shape\n",
    "        self.transformer.build([enc_input, dec_input])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        enc_input, dec_input, dec_output = input_shape\n",
    "        return self.transformer.compute_output_shape([enc_input, dec_input])\n",
    "\n",
    "    def compute_padding_mask(self, inp):\n",
    "        mask = tf.cast(tf.math.not_equal(inp, 0), tf.float32)\n",
    "        mask = mask[:, tf.newaxis, tf.newaxis, :]\n",
    "        return mask\n",
    "    \n",
    "    def compute_padding_lookahead_mask(self, decoder_inp):\n",
    "        mask = tf.cast(tf.math.equal(decoder_inp, 0), tf.float32)\n",
    "        mask = mask[:, tf.newaxis, tf.newaxis, :]\n",
    "        return tf.cast(tf.maximum(mask, 1 - tf.linalg.band_part(tf.ones((decoder_inp.shape[-1], decoder_inp.shape[-1])), -1, 0)) == 0, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoder_inputs, decoder_inputs, targets = inputs\n",
    "        encoder_mask = self.compute_padding_mask(encoder_inputs)\n",
    "        decoder_mask = self.compute_padding_lookahead_mask(decoder_inputs)\n",
    "\n",
    "        return self.transformer(encoder_inputs, decoder_inputs, encoder_mask, decoder_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, inputs):\n",
    "        encoder_inputs, decoder_inputs, targets = inputs\n",
    "\n",
    "        loss = None\n",
    "        encoder_mask = self.compute_padding_mask(encoder_inputs)\n",
    "        decoder_mask = self.compute_padding_lookahead_mask(decoder_inputs)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits, _, _ = self.transformer(encoder_inputs, decoder_inputs, encoder_mask, decoder_mask, training=True)\n",
    "            loss = self.loss(targets, logits, tf.cast(tf.math.not_equal(targets, 0), tf.float32), self.label_smoothing)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.transformer.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.transformer.trainable_variables))\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "\n",
    "        return {'loss': self.loss_tracker.result()}\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, inputs):\n",
    "        encoder_inputs, decoder_inputs, targets = inputs\n",
    "        encoder_mask = self.compute_padding_mask(encoder_inputs)\n",
    "        decoder_mask = self.compute_padding_lookahead_mask(decoder_inputs)\n",
    "        \n",
    "        logits, _, _ = self.transformer(encoder_inputs, decoder_inputs, encoder_mask, decoder_mask, training=False)\n",
    "        loss = self.loss(targets, logits, mask=tf.cast(tf.math.not_equal(targets, 0), tf.float32), label_smoothing=0.0)\n",
    "\n",
    "        self.val_loss_tracker.update_state(loss)\n",
    "\n",
    "        return {'loss': self.val_loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5f06f67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:33.103764Z",
     "iopub.status.busy": "2025-05-05T06:18:33.103527Z",
     "iopub.status.idle": "2025-05-05T06:18:33.107392Z",
     "shell.execute_reply": "2025-05-05T06:18:33.106205Z"
    },
    "papermill": {
     "duration": 0.011968,
     "end_time": "2025-05-05T06:18:33.108658",
     "exception": false,
     "start_time": "2025-05-05T06:18:33.096690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "107424f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:33.122752Z",
     "iopub.status.busy": "2025-05-05T06:18:33.122461Z",
     "iopub.status.idle": "2025-05-05T06:18:35.223345Z",
     "shell.execute_reply": "2025-05-05T06:18:35.222393Z"
    },
    "papermill": {
     "duration": 2.109766,
     "end_time": "2025-05-05T06:18:35.225069",
     "exception": false,
     "start_time": "2025-05-05T06:18:33.115303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tformer = Transformer(parameters['ENCODER_LAYERS'], parameters['DECODER_LAYERS'], parameters['EMBEDDING_DIMENSION'], parameters['ENCODER_SEQUENCE_LENGTH'], parameters['DECODER_SEQUENCE_LENGTH'], parameters['VOC_SIZE'], parameters['VOC_SIZE'], parameters['ENCODER_ATTENTION_HEADS'], parameters['DECODER_ATTENTION_HEADS'], parameters['ENCODER_FFN_DIM'], parameters['DECODER_FFN_DIM'])\n",
    "model = TransformerTrainer(tformer, parameters['LABEL_SMOOTHING'])\n",
    "model.build(((None, parameters['ENCODER_SEQUENCE_LENGTH']), (None, parameters['DECODER_SEQUENCE_LENGTH']), (None, parameters['DECODER_SEQUENCE_LENGTH'])))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=parameters['LEARNING_RATE'], weight_decay=parameters['L2_REG']), loss=cross_entropy_loss, run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b04adb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:35.239403Z",
     "iopub.status.busy": "2025-05-05T06:18:35.239118Z",
     "iopub.status.idle": "2025-05-05T06:18:35.258031Z",
     "shell.execute_reply": "2025-05-05T06:18:35.257173Z"
    },
    "papermill": {
     "duration": 0.027517,
     "end_time": "2025-05-05T06:18:35.259484",
     "exception": false,
     "start_time": "2025-05-05T06:18:35.231967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_trainer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer_trainer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ transformer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Transformer</span>)            │ ((<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50000</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">55,881,552</span> │\n",
       "│                                      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, │                 │\n",
       "│                                      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>))                       │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ transformer (\u001b[38;5;33mTransformer\u001b[0m)            │ ((\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m50000\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,  │      \u001b[38;5;34m55,881,552\u001b[0m │\n",
       "│                                      │ \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m12\u001b[0m, │                 │\n",
       "│                                      │ \u001b[38;5;34m256\u001b[0m))                       │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,881,552</span> (213.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,881,552\u001b[0m (213.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,881,552</span> (213.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,881,552\u001b[0m (213.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fe04b20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:35.274755Z",
     "iopub.status.busy": "2025-05-05T06:18:35.274457Z",
     "iopub.status.idle": "2025-05-05T06:18:35.285244Z",
     "shell.execute_reply": "2025-05-05T06:18:35.284299Z"
    },
    "papermill": {
     "duration": 0.019985,
     "end_time": "2025-05-05T06:18:35.286799",
     "exception": false,
     "start_time": "2025-05-05T06:18:35.266814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GenerationCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, df:pd.DataFrame, encoder_seq_len:int, decoder_seq_len: int, tokenizer, sos_id:int, eos_id:int, pad_id:int=0, **kwargs):\n",
    "        self.df = df\n",
    "        self.encoder_seq_len = encoder_seq_len\n",
    "        self.decoder_seq_len = decoder_seq_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_id = pad_id\n",
    "        self.sos_id = sos_id\n",
    "        self.eos_id = eos_id\n",
    "\n",
    "    def generate(self):\n",
    "        generated = []\n",
    "        for news, title in self.df.sample(n=2).values.tolist():\n",
    "            news_encoded = self.tokenizer.encode(news)\n",
    "        \n",
    "            if len(news_encoded) >= self.encoder_seq_len:\n",
    "                news_encoded = news_encoded[:self.encoder_seq_len]\n",
    "            else:\n",
    "                news_encoded = news_encoded + [self.pad_id] * (self.encoder_seq_len - len(news_encoded))\n",
    "        \n",
    "            encoder_mask = tf.cast(tf.math.not_equal([news_encoded], 0), tf.float32)\n",
    "            encoder_mask = encoder_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "        \n",
    "            enc_outputs, enc_attn_wts = self.model.transformer.encoder(tf.convert_to_tensor([news_encoded]), mask=encoder_mask, training=False)\n",
    "            \n",
    "            decoder_input = tf.fill([1,1], self.sos_id)\n",
    "        \n",
    "            for t in range(self.decoder_seq_len):\n",
    "                decoder_mask = tf.cast(tf.math.equal(decoder_input, 0), tf.float32)\n",
    "                decoder_mask = decoder_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "                decoder_mask = tf.cast(tf.maximum(decoder_mask, 1 - tf.linalg.band_part(tf.ones((decoder_input.shape[-1], decoder_input.shape[-1])), -1, 0)) == 0, tf.float32)\n",
    "        \n",
    "                dec_outputs, dec_attn_wts = self.model.transformer.decoder(decoder_input, enc_outputs, encoder_mask=encoder_mask, decoder_mask=decoder_mask, training=False)\n",
    "                final_dist = self.model.transformer.projection(dec_outputs[:,-1])\n",
    "                curr_output = tf.expand_dims(tf.argmax(final_dist, -1, output_type=tf.int32), 1)\n",
    "                if curr_output[0] == self.eos_id:\n",
    "                    break\n",
    "                decoder_input = tf.concat([decoder_input, curr_output], -1)\n",
    "            generated.append([title, self.tokenizer.decode(tf.squeeze(decoder_input, 0).numpy().tolist())])\n",
    "        return generated\n",
    "    # def on_epoch_begin(self, epoch, logs=None):\n",
    "        ## 1 for first epoch(0)\n",
    "        # self.model.teacher_forcing_ratio = 0.9**epoch\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        generated_titles = self.generate()\n",
    "        print(\"\\n\")\n",
    "        for ref, pred in generated_titles:\n",
    "            print(f\"REF: {ref}, PRED: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b821bb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:35.302077Z",
     "iopub.status.busy": "2025-05-05T06:18:35.301774Z",
     "iopub.status.idle": "2025-05-05T06:18:35.311130Z",
     "shell.execute_reply": "2025-05-05T06:18:35.310351Z"
    },
    "papermill": {
     "duration": 0.018229,
     "end_time": "2025-05-05T06:18:35.312405",
     "exception": false,
     "start_time": "2025-05-05T06:18:35.294176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpk = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='/kaggle/working/best.weights.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    ")\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode=\"min\", patience=parameters['EARLY_STOPPING'])\n",
    "gc = GenerationCallback(df_eval.sample(n=100), parameters['ENCODER_SEQUENCE_LENGTH'], parameters['DECODER_SEQUENCE_LENGTH'], sp, parameters['SOS_TOKEN_ID'], parameters['EOS_TOKEN_ID'], parameters['PAD_TOKEN_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdcd3956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T06:18:35.327895Z",
     "iopub.status.busy": "2025-05-05T06:18:35.327619Z",
     "iopub.status.idle": "2025-05-05T12:40:42.443360Z",
     "shell.execute_reply": "2025-05-05T12:40:42.442427Z"
    },
    "papermill": {
     "duration": 22930.059533,
     "end_time": "2025-05-05T12:40:45.379273",
     "exception": false,
     "start_time": "2025-05-05T06:18:35.319740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - loss: 8.4677\n",
      "\n",
      "REF: खेलकुदको शहर खेलकुदमै टुहुरो, PRED: राष्ट्रिय प्रदेश प्रदेश १ मा\n",
      "REF: आर्टिफिसियल इन्टेलिजेन्स अन्तर्राष्ट्रिय कार्यशाला शुरु, PRED: नेपाल बैंकको लगानी\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1705s\u001b[0m 408ms/step - loss: 8.4676 - val_loss: 6.6108\n",
      "Epoch 2/20\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 6.9683\n",
      "\n",
      "REF: पुटिनले अचानक युक्रेन विरुद्ध अर्को निर्णय लिए, PRED: अमेरिकी अमेरिकी हतियार प्रयोग गर्न प्रतिबन्ध\n",
      "REF: बलिउडकै महंगो विवाह रणवीर र दीपिकाले यस्तो ठाउँ रोजे, PRED: सलमान खान को पहिलो पटक\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1634s\u001b[0m 401ms/step - loss: 6.9682 - val_loss: 5.7458\n",
      "Epoch 3/20\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 6.2738\n",
      "\n",
      "REF: कांग्रेस भित्र यस्ता छन् गुट र उपगुटहरू, PRED: कांग्रेस केन्द्रीय कमिटी बैठक बस्दै\n",
      "REF: प्रभुराम शर्मा प्रधानसेनापतिमा नियुक्त, PRED: राष्ट्रपतिद्वारा पदभार ग्रहण\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1633s\u001b[0m 401ms/step - loss: 6.2737 - val_loss: 5.2190\n",
      "Epoch 4/20\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 5.7780\n",
      "\n",
      "REF: मधेसका ५४० सहिद परिवारलाई एक लाखको दरले आर्थिक सहयोग, PRED: प्रधानमन्त्रीद्वारा एक लाख ५० लाख रुपैयाँ सहयोग\n",
      "REF: आर्मीलाई एमएम कप उपाधि, PRED: आर्मी च्याम्पियन च्याम्पियन\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1632s\u001b[0m 401ms/step - loss: 5.7780 - val_loss: 4.8594\n",
      "Epoch 5/20\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 5.3879\n",
      "\n",
      "REF: अमेरिकामा एक दशकपछि पहिलो पोलियोको बिरामी भेटियो, PRED: अमेरिकामा एक हप्ता सङ्क्रमित\n",
      "REF: अमलेखगञ्ज दुर्घटना अपडेट थप उपचारका लागि घाइतेहरुलाई चितवन पठाईयो, PRED: बस दुर्घटनामा घाइते भएका एक जना घाइते\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1633s\u001b[0m 401ms/step - loss: 5.3879 - val_loss: 4.6124\n",
      "Epoch 6/20\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 5.0627\n",
      "\n",
      "REF: भ्यालेन्टाइन डे मा मोडल प्रकृतिले भेट्न नमान्दा, PRED: भ्यालेन्टाइन डे मनाइँदै\n",
      "REF: खेलकुदको शहर खेलकुदमै टुहुरो, PRED: खेलकुद गण्डकी खेलकुद छनोट\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1633s\u001b[0m 401ms/step - loss: 5.0627 - val_loss: 4.4386\n",
      "Epoch 7/20\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 4.7800\n",
      "\n",
      "REF: बेलायतमा कञ्जरभेटिभ पार्टीको बहुमत जोन्सन पुन प्रधानमन्त्री बन्ने, PRED: बेलायतको नयाँ प्रधानमन्त्री\n",
      "REF: गाईसँग ठोक्किएर मोटरसाइकल चालकको मृत्यु, PRED: झापामा मोटरसाइकल दुर्घटना हुँदा चालकको मृत्यु\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1629s\u001b[0m 400ms/step - loss: 4.7799 - val_loss: 4.3305\n",
      "Epoch 8/20\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 4.5281\n",
      "\n",
      "REF: बालबालिकालाई टीभीमा स्वतन्त्र छोड्नु घातक, PRED: विद्यार्थीलाई हल\n",
      "REF: प्रभुराम शर्मा प्रधानसेनापतिमा नियुक्त, PRED: प्रधानसेनापति शर्माद्वारा प्रधानसेनापति शर्मा नियुक्त\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1625s\u001b[0m 399ms/step - loss: 4.5281 - val_loss: 4.2708\n",
      "Epoch 9/20\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 4.3014\n",
      "\n",
      "REF: बुटवल उपमहानगरपालिकामा पूर्ण खोप सुनिश्चित भएको घोषणा, PRED: बुटवल उपमहानगर पूर्ण खोप सुनिश्चितता तथा दिगोपना घोषणा\n",
      "REF: राष्ट्रिय आवश्यकताका लागि गठबन्धन गरिएको हो प्रधानमन्त्री देउवा, PRED: राष्ट्रिय सहमतिको खाका प्रधानमन्त्री देउवा\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1628s\u001b[0m 400ms/step - loss: 4.3014 - val_loss: 4.2213\n",
      "Epoch 10/20\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 4.0961\n",
      "\n",
      "REF: नेदरल्याण्डमाथि नेपालको शानदार जित, PRED: नेपालको पहिलो जित\n",
      "REF: आज इन्द्रजात्रा पर्व मनाइँदै उपत्यकामा सार्वजनिक विदा, PRED: आज इन्द्रजात्रा मनाइँदै\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1629s\u001b[0m 400ms/step - loss: 4.0961 - val_loss: 4.2112\n",
      "Epoch 11/20\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 3.9109\n",
      "\n",
      "REF: कृषि कानुनको विरोधमा भारतको राज्यसभा बैठक अवरुद्ध, PRED: संसदमा अवरोधपछि संसद् बैठक स्थगित\n",
      "REF: सरकारी भवन शहरी विकास मन्त्रालयले नै बनाउन निर्देशन, PRED: सरकारी भवन बनाउन निर्देशन\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1634s\u001b[0m 401ms/step - loss: 3.9109 - val_loss: 4.2142\n",
      "Epoch 12/20\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - loss: 3.7397\n",
      "\n",
      "REF: पोल्यान्डलाई फ्रान्सले कमजोर नठान्ने, PRED: नब्बे वर्षीय मेसीबिना पनि फ्रान्स छाड्ने\n",
      "REF: चिनियाँ स्मार्टफोन कम्पनी ओप्पोले बजारमा ल्यायो आफ्नो फोल्डेबल फ्लिप फोन, PRED: जियोफोन सन् २०२५ मा बन्द हुने स्मार्टफोन चीनमा आउने\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1638s\u001b[0m 402ms/step - loss: 3.7397 - val_loss: 4.2325\n",
      "Epoch 13/20\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - loss: 3.5849\n",
      "\n",
      "REF: रुसी आक्रमणबाट पूर्वी युक्रेनमा ३ जनाको मृत्यु, PRED: पूर्वी युक्रेनमा रुसी आक्रमण तीन जनाको मृत्यु\n",
      "REF: बुटवल उपमहानगरपालिकामा पूर्ण खोप सुनिश्चित भएको घोषणा, PRED: बुटवल उपमहानगरद्वारा खोप सुनिश्चितता तथा दिगोपना घोषणा\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1637s\u001b[0m 402ms/step - loss: 3.5849 - val_loss: 4.2753\n",
      "Epoch 14/20\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - loss: 3.4441\n",
      "\n",
      "REF: अमेरिकामा गोली चल्दा चारजनाको मृत्यु कैयौँ घाइते, PRED: अमेरिकामा गोली चल्दा ४ जनाको मृत्यु ४ घाइते\n",
      "REF: च्याम्पियन्स लिगमा नेइमारमाथि लागेको प्रतिबन्ध घटाइयो, PRED: च्याम्पियन्स लिगमा म्यानचेस्टर युनाइटेड माथि प्रतिबन्ध\n",
      "\u001b[1m4075/4075\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1638s\u001b[0m 402ms/step - loss: 3.4441 - val_loss: 4.3260\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, epochs=parameters[\"EPOCHS\"], batch_size=parameters[\"BATCH_SIZE\"], validation_data=test, callbacks=[cpk, es, gc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6f72b49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T12:40:51.289448Z",
     "iopub.status.busy": "2025-05-05T12:40:51.289134Z",
     "iopub.status.idle": "2025-05-05T12:40:53.211500Z",
     "shell.execute_reply": "2025-05-05T12:40:53.210788Z"
    },
    "papermill": {
     "duration": 4.85195,
     "end_time": "2025-05-05T12:40:53.213083",
     "exception": false,
     "start_time": "2025-05-05T12:40:48.361133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_weights('/kaggle/working/model.weights.h5')\n",
    "with open('/train_history', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bab5f15d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T12:40:59.175513Z",
     "iopub.status.busy": "2025-05-05T12:40:59.175203Z",
     "iopub.status.idle": "2025-05-05T12:40:59.181138Z",
     "shell.execute_reply": "2025-05-05T12:40:59.180266Z"
    },
    "papermill": {
     "duration": 2.981588,
     "end_time": "2025-05-05T12:40:59.182377",
     "exception": false,
     "start_time": "2025-05-05T12:40:56.200789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [7.934503078460693,\n",
       "  6.765522003173828,\n",
       "  6.139360427856445,\n",
       "  5.673072338104248,\n",
       "  5.30250883102417,\n",
       "  4.989997863769531,\n",
       "  4.715693950653076,\n",
       "  4.471354961395264,\n",
       "  4.250297546386719,\n",
       "  4.050029277801514,\n",
       "  3.8695437908172607,\n",
       "  3.702496290206909,\n",
       "  3.5523335933685303,\n",
       "  3.4147582054138184],\n",
       " 'val_loss': [6.610799789428711,\n",
       "  5.745779037475586,\n",
       "  5.2190260887146,\n",
       "  4.859400272369385,\n",
       "  4.612404823303223,\n",
       "  4.438576698303223,\n",
       "  4.330516815185547,\n",
       "  4.270757675170898,\n",
       "  4.221330165863037,\n",
       "  4.211203575134277,\n",
       "  4.214169025421143,\n",
       "  4.232534885406494,\n",
       "  4.275265693664551,\n",
       "  4.3260369300842285]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/train_history', \"rb\") as f:\n",
    "    history = pickle.load(f)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d3a4a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T12:41:05.003394Z",
     "iopub.status.busy": "2025-05-05T12:41:05.003055Z",
     "iopub.status.idle": "2025-05-05T12:41:05.718293Z",
     "shell.execute_reply": "2025-05-05T12:41:05.717230Z"
    },
    "papermill": {
     "duration": 3.787513,
     "end_time": "2025-05-05T12:41:05.719925",
     "exception": false,
     "start_time": "2025-05-05T12:41:01.932412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tformer_trained = Transformer(parameters['ENCODER_LAYERS'], parameters['DECODER_LAYERS'], parameters['EMBEDDING_DIMENSION'], parameters['ENCODER_SEQUENCE_LENGTH'], parameters['DECODER_SEQUENCE_LENGTH'], parameters['VOC_SIZE'], parameters['VOC_SIZE'], parameters['ENCODER_ATTENTION_HEADS'], parameters['DECODER_ATTENTION_HEADS'], parameters['ENCODER_FFN_DIM'], parameters['DECODER_FFN_DIM'])\n",
    "model_trained = TransformerTrainer(tformer_trained, parameters['LABEL_SMOOTHING'])\n",
    "model_trained.build(((None, parameters['ENCODER_SEQUENCE_LENGTH']), (None, parameters['DECODER_SEQUENCE_LENGTH']), (None, parameters['DECODER_SEQUENCE_LENGTH'])))\n",
    "model_trained.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=parameters['LEARNING_RATE'], weight_decay=parameters['L2_REG']), loss=cross_entropy_loss, run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d76880b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T12:41:11.602033Z",
     "iopub.status.busy": "2025-05-05T12:41:11.601672Z",
     "iopub.status.idle": "2025-05-05T12:41:12.310984Z",
     "shell.execute_reply": "2025-05-05T12:41:12.310070Z"
    },
    "papermill": {
     "duration": 3.660951,
     "end_time": "2025-05-05T12:41:12.312350",
     "exception": false,
     "start_time": "2025-05-05T12:41:08.651399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 518 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model_trained.load_weights('/kaggle/working/model.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367cdea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T12:41:18.160572Z",
     "iopub.status.busy": "2025-05-05T12:41:18.160233Z",
     "iopub.status.idle": "2025-05-05T12:41:18.167483Z",
     "shell.execute_reply": "2025-05-05T12:41:18.166613Z"
    },
    "papermill": {
     "duration": 2.926075,
     "end_time": "2025-05-05T12:41:18.168802",
     "exception": false,
     "start_time": "2025-05-05T12:41:15.242727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(model, news, encoder_seq_len, decoder_seq_len, tokenizer, sos_id, eos_id, pad_id):\n",
    "    news_encoded = tokenizer.encode(news)\n",
    "    \n",
    "    if len(news_encoded) >= encoder_seq_len:\n",
    "        news_encoded = news_encoded[:encoder_seq_len]\n",
    "    else:\n",
    "        news_encoded = news_encoded + [pad_id] * (encoder_seq_len - len(news_encoded))\n",
    "\n",
    "    output_seq = []\n",
    "\n",
    "    encoder_mask = tf.cast(tf.math.not_equal([news_encoded], 0), tf.float32)\n",
    "    encoder_mask = encoder_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    enc_outputs, enc_attn_wts = model.transformer.encoder(tf.convert_to_tensor([news_encoded]), mask=encoder_mask, training=False)\n",
    "    \n",
    "    decoder_input = tf.fill([1,1], sos_id)\n",
    "\n",
    "    for t in range(decoder_seq_len):\n",
    "        decoder_mask = tf.cast(tf.math.equal(decoder_input, 0), tf.float32)\n",
    "        decoder_mask = decoder_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "        decoder_mask = tf.cast(tf.maximum(decoder_mask, 1 - tf.linalg.band_part(tf.ones((decoder_input.shape[-1], decoder_input.shape[-1])), -1, 0)) == 0, tf.float32)\n",
    "\n",
    "        dec_outputs, dec_attn_wts = model.transformer.decoder(decoder_input, enc_outputs, encoder_mask=encoder_mask, decoder_mask=decoder_mask, training=False)\n",
    "        final_dist = model.transformer.projection(dec_outputs[:,-1])\n",
    "        curr_output = tf.expand_dims(tf.argmax(final_dist, -1, output_type=tf.int32), 1)\n",
    "        if curr_output[0] == eos_id:\n",
    "            break\n",
    "        decoder_input = tf.concat([decoder_input, curr_output], -1)\n",
    "    return tokenizer.decode(tf.squeeze(decoder_input, 0).numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9496a02b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T12:41:24.076983Z",
     "iopub.status.busy": "2025-05-05T12:41:24.076560Z",
     "iopub.status.idle": "2025-05-05T12:41:26.333932Z",
     "shell.execute_reply": "2025-05-05T12:41:26.332944Z"
    },
    "papermill": {
     "duration": 5.414783,
     "end_time": "2025-05-05T12:41:26.335365",
     "exception": false,
     "start_time": "2025-05-05T12:41:20.920582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model_trained, df_eval['news'].iloc[1], 256, 12, sp, sp.bos_id(), sp.eos_id(), sp.pad_id())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7006724,
     "sourceId": 11219687,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7006736,
     "sourceId": 11219703,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23462.837376,
   "end_time": "2025-05-05T12:41:32.282273",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-05T06:10:29.444897",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
