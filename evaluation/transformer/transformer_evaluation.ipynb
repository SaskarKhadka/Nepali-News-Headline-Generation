{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14aa347b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-05T19:58:53.881424Z",
     "iopub.status.busy": "2025-05-05T19:58:53.881118Z",
     "iopub.status.idle": "2025-05-05T19:59:24.468030Z",
     "shell.execute_reply": "2025-05-05T19:59:24.466847Z"
    },
    "papermill": {
     "duration": 30.597461,
     "end_time": "2025-05-05T19:59:24.469904",
     "exception": false,
     "start_time": "2025-05-05T19:58:53.872443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:59:07.145895: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746475147.537919      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746475147.633070      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "import random\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Input, Dense, TimeDistributed, Embedding, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import pickle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7739f1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:24.486535Z",
     "iopub.status.busy": "2025-05-05T19:59:24.485251Z",
     "iopub.status.idle": "2025-05-05T19:59:24.490943Z",
     "shell.execute_reply": "2025-05-05T19:59:24.489850Z"
    },
    "papermill": {
     "duration": 0.016023,
     "end_time": "2025-05-05T19:59:24.492730",
     "exception": false,
     "start_time": "2025-05-05T19:59:24.476707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.keras.backend.clear_session()\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     for gpu in gpus:\n",
    "#        tf.config.experimental.set_memory_growth(gpu,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e3b7c70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:24.510406Z",
     "iopub.status.busy": "2025-05-05T19:59:24.510077Z",
     "iopub.status.idle": "2025-05-05T19:59:24.577535Z",
     "shell.execute_reply": "2025-05-05T19:59:24.576601Z"
    },
    "papermill": {
     "duration": 0.077041,
     "end_time": "2025-05-05T19:59:24.579061",
     "exception": false,
     "start_time": "2025-05-05T19:59:24.502020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"/kaggle/input/nepali-summarization-tokenizer/summarization_50000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed38cd2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:24.593099Z",
     "iopub.status.busy": "2025-05-05T19:59:24.592760Z",
     "iopub.status.idle": "2025-05-05T19:59:24.599120Z",
     "shell.execute_reply": "2025-05-05T19:59:24.598043Z"
    },
    "papermill": {
     "duration": 0.01467,
     "end_time": "2025-05-05T19:59:24.600510",
     "exception": false,
     "start_time": "2025-05-05T19:59:24.585840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'VOC_SIZE': 50_000,\n",
    "\n",
    "    'ENCODER_LAYERS': 6,\n",
    "    'DECODER_LAYERS': 6,\n",
    "\n",
    "    'ENCODER_SEQUENCE_LENGTH': 256,\n",
    "    'DECODER_SEQUENCE_LENGTH': 12,\n",
    "    \n",
    "    'EMBEDDING_DIMENSION': 256,\n",
    "    'ENCODER_ATTENTION_HEADS': 8,\n",
    "    'DECODER_ATTENTION_HEADS': 8,\n",
    "    'ENCODER_FFN_DIM': 4 * 512,\n",
    "    'DECODER_FFN_DIM': 4 * 512,\n",
    "    \n",
    "    'DROPOUT': 0.2,\n",
    "\n",
    "    'BATCH_SIZE': 64,\n",
    "    'EPOCHS': 20,\n",
    "    'EARLY_STOPPING': 4,\n",
    "    'L2_REG': 0.01,\n",
    "    \n",
    "    'LEARNING_RATE': 1e-4,\n",
    "\n",
    "    'LABEL_SMOOTHING': 0.1,\n",
    "    'TEACHER_FORCING_RATIO': 0.5,\n",
    "    'GRAD_CLIP': 1.0,\n",
    "\n",
    "    'PAD_TOKEN': '<pad>',\n",
    "    'UNK_TOKEN': '<unk>',\n",
    "    'SOS_TOKEN': '<s>',\n",
    "    'EOS_TOKEN': '</s>',\n",
    "\n",
    "    'PAD_TOKEN_ID': sp.pad_id(),\n",
    "    'UNK_TOKEN_ID': sp.unk_id(),\n",
    "    'SOS_TOKEN_ID': sp.bos_id(),\n",
    "    'EOS_TOKEN_ID': sp.eos_id(),\n",
    "\n",
    "    'COVERAGE_WEIGHT': 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3aa1032",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:24.614357Z",
     "iopub.status.busy": "2025-05-05T19:59:24.614065Z",
     "iopub.status.idle": "2025-05-05T19:59:29.960473Z",
     "shell.execute_reply": "2025-05-05T19:59:29.959587Z"
    },
    "papermill": {
     "duration": 5.355219,
     "end_time": "2025-05-05T19:59:29.962261",
     "exception": false,
     "start_time": "2025-05-05T19:59:24.607042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(\"/kaggle/input/nepali-summarization-set-cleaned/summarization_set_cleaned_val.csv\")\n",
    "df_test = pd.read_csv(\"/kaggle/input/nepali-summarization-set-cleaned/summarization_set_cleaned_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a23f80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:29.976078Z",
     "iopub.status.busy": "2025-05-05T19:59:29.975738Z",
     "iopub.status.idle": "2025-05-05T19:59:29.984005Z",
     "shell.execute_reply": "2025-05-05T19:59:29.983193Z"
    },
    "papermill": {
     "duration": 0.016723,
     "end_time": "2025-05-05T19:59:29.985417",
     "exception": false,
     "start_time": "2025-05-05T19:59:29.968694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Embeddings(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model: int, seq_len: int, voc_size: int, dropout_rate: float = 0.1, **kwargs):\n",
    "        super(Embeddings, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.voc_size = voc_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.input_emb = tf.keras.layers.Embedding(self.voc_size, self.d_model, name='Sequence_Embedding')\n",
    "        self.positional_emb = tf.keras.layers.Embedding(self.seq_len, self.d_model, name='Positional_Embedding')\n",
    "        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_emb.build(input_shape)\n",
    "        self.positional_emb.build(input_shape)\n",
    "        output_shape = self.input_emb.compute_output_shape(input_shape)\n",
    "        self.dropout.build(output_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.input_emb.compute_output_shape(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # inputs -> (batch, seq_len)\n",
    "        positions = tf.repeat(tf.expand_dims(tf.range(tf.shape(inputs)[1]), 0), [tf.shape(inputs)[0]], axis=0) # (batch, seq_len) \n",
    "        inp_emb = self.input_emb(inputs) # (batch, seq_len, d_model)\n",
    "        pos_emb = self.positional_emb(positions) # (batch, seq_len, d_model)\n",
    "\n",
    "        return self.dropout(inp_emb + pos_emb, training=training) # (batch, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e873a49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:29.998880Z",
     "iopub.status.busy": "2025-05-05T19:59:29.998550Z",
     "iopub.status.idle": "2025-05-05T19:59:30.012451Z",
     "shell.execute_reply": "2025-05-05T19:59:30.011660Z"
    },
    "papermill": {
     "duration": 0.022489,
     "end_time": "2025-05-05T19:59:30.014090",
     "exception": false,
     "start_time": "2025-05-05T19:59:29.991601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model: int, h: int, dropout_rate: float = 0.1, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        assert d_model % h == 0\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        self.d_k = self.d_model // self.h\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.w_q = tf.keras.layers.Dense(self.d_model) \n",
    "        self.w_k = tf.keras.layers.Dense(self.d_model) \n",
    "        self.w_v = tf.keras.layers.Dense(self.d_model) \n",
    "        self.w_o = tf.keras.layers.Dense(self.d_model)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        q, k, v = input_shape\n",
    "        self.w_q.build(q)\n",
    "        self.w_k.build(k)\n",
    "        self.w_v.build(v)\n",
    "        self.w_o.build(q)\n",
    "        self.dropout.build(q)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        q, k, v = input_shape\n",
    "        return self.dropout.compute_output_shape(q), (q[0], self.h, q[1], k[1]) \n",
    "        \n",
    "    def scaled_dot_product_attention(self, q, k, v, mask=None):\n",
    "        attn_score = q @ tf.transpose(k, perm=[0,1,3,2]) / tf.sqrt(tf.cast(k.shape[-1], dtype=tf.float32))\n",
    "        if mask is not None:\n",
    "            # attn_score += (mask * -1e9)\n",
    "            attn_score = tf.where(mask==0, -1e9, attn_score) # Set very small values where mask = 0\n",
    "            \n",
    "        attn_wts = tf.nn.softmax(attn_score, -1) # (batch, h, seq_len, seq_len) seq_len*seq_len because self attention\n",
    "        outputs = attn_wts @ v # (batch, h, seq_len, d_k)\n",
    "        return outputs, attn_wts\n",
    "\n",
    "    def call(self, q, k, v, mask=None, training=False):\n",
    "        q = self.w_q(q) # (batch, seq_len, d_model)\n",
    "        k = self.w_k(k)\n",
    "        v = self.w_v(v)\n",
    "\n",
    "        # Convert (batch, seq_len, d_model) to (batch, h, seq_len, d_k)\n",
    "        # Split d_model into h*d_k and then transpose the 2nd and 3rd dimension\n",
    "        q = tf.transpose(tf.reshape(q, [tf.shape(q)[0], tf.shape(q)[1], self.h, self.d_k]), perm=[0,2,1,3])\n",
    "        k = tf.transpose(tf.reshape(k, [tf.shape(k)[0], tf.shape(k)[1], self.h, self.d_k]), perm=[0,2,1,3])\n",
    "        v = tf.transpose(tf.reshape(v, [tf.shape(v)[0], tf.shape(v)[1], self.h, self.d_k]), perm=[0,2,1,3])\n",
    "\n",
    "        outputs, attn_weights = self.scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        # First Convert (batch, h, seq_len, d_k) to (batch, seq_len, d_model)\n",
    "        # Reverse the above operations\n",
    "        # Run through Dense to get (batch, seq_len, d_model) \n",
    "        outputs = self.w_o(tf.reshape(tf.transpose(outputs, perm=[0,2,1,3]), [tf.shape(outputs)[0], tf.shape(outputs)[2], self.d_model]))\n",
    "\n",
    "        return self.dropout(outputs, training=training), attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fad29670",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:30.027191Z",
     "iopub.status.busy": "2025-05-05T19:59:30.026897Z",
     "iopub.status.idle": "2025-05-05T19:59:30.033061Z",
     "shell.execute_reply": "2025-05-05T19:59:30.032121Z"
    },
    "papermill": {
     "duration": 0.014474,
     "end_time": "2025-05-05T19:59:30.034642",
     "exception": false,
     "start_time": "2025-05-05T19:59:30.020168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class AddAndNorm(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AddAndNorm, self).__init__(**kwargs)\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.layer_norm.build(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.layer_norm.compute_output_shape(input_shape)\n",
    "        \n",
    "    def call(self, skip_conn, output):\n",
    "        return self.layer_norm(skip_conn + output) # (batch, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b95c20e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:30.048017Z",
     "iopub.status.busy": "2025-05-05T19:59:30.047689Z",
     "iopub.status.idle": "2025-05-05T19:59:30.055318Z",
     "shell.execute_reply": "2025-05-05T19:59:30.054381Z"
    },
    "papermill": {
     "duration": 0.016079,
     "end_time": "2025-05-05T19:59:30.056936",
     "exception": false,
     "start_time": "2025-05-05T19:59:30.040857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class PositionwiseFeedForwardNetwork(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout_rate: float = 0.1, **kwargs):\n",
    "        super(PositionwiseFeedForwardNetwork, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.inner = tf.keras.layers.Dense(self.d_ff, activation='relu')\n",
    "        self.outer = tf.keras.layers.Dense(self.d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.inner.build(input_shape)\n",
    "        output = self.inner.compute_output_shape(input_shape)\n",
    "        self.outer.build(output)\n",
    "        self.dropout.build(self.outer.compute_output_shape(output))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.outer.compute_output_shape(self.inner.compute_output_shape(input_shape))\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.inner(inputs) # (batch, seq_len, d_ff)\n",
    "        x = self.outer(x) # (batch, seq_len, d_model)\n",
    "        return self.dropout(x, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "086565a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:30.070469Z",
     "iopub.status.busy": "2025-05-05T19:59:30.070172Z",
     "iopub.status.idle": "2025-05-05T19:59:30.078161Z",
     "shell.execute_reply": "2025-05-05T19:59:30.077242Z"
    },
    "papermill": {
     "duration": 0.016453,
     "end_time": "2025-05-05T19:59:30.079571",
     "exception": false,
     "start_time": "2025-05-05T19:59:30.063118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class EncoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model: int, h:int, d_ff: int, dropout_rate: float = 0.1, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.mhsa = MultiHeadAttention(self.d_model, self.h, self.dropout_rate)\n",
    "        self.add_norm1 = AddAndNorm()\n",
    "        self.pffn = PositionwiseFeedForwardNetwork(self.d_model, self.d_ff, self.dropout_rate)\n",
    "        self.add_norm2 = AddAndNorm()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mhsa.build([input_shape, input_shape, input_shape])\n",
    "        self.add_norm1.build(input_shape)\n",
    "        self.pffn.build(input_shape)\n",
    "        self.add_norm2.build(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.mhsa.compute_output_shape([input_shape, input_shape, input_shape])\n",
    "\n",
    "    def call(self, inputs, mask=None, training=False):\n",
    "        mhsa_outputs, attn_weights = self.mhsa(inputs, inputs, inputs, mask, training=training)\n",
    "        x = self.add_norm1(inputs, mhsa_outputs)\n",
    "        pffn_outputs = self.pffn(x, training=training)\n",
    "        x = self.add_norm2(x, pffn_outputs)\n",
    "        \n",
    "        return x, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0209a9ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:30.093370Z",
     "iopub.status.busy": "2025-05-05T19:59:30.093060Z",
     "iopub.status.idle": "2025-05-05T19:59:30.101766Z",
     "shell.execute_reply": "2025-05-05T19:59:30.100840Z"
    },
    "papermill": {
     "duration": 0.017712,
     "end_time": "2025-05-05T19:59:30.103333",
     "exception": false,
     "start_time": "2025-05-05T19:59:30.085621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, N: int, d_model: int, seq_len: int, voc_size: int, h:int, d_ff: int, dropout_rate: float = 0.1, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        assert N > 0\n",
    "        self.N = N\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.voc_size = voc_size\n",
    "        self.h = h\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.embedding = Embeddings(self.d_model, self.seq_len, self.voc_size, self.dropout_rate)\n",
    "        self.enc_layers = [EncoderBlock(self.d_model, self.h, self.d_ff, self.dropout_rate) for _ in range(self.N)]\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embedding.build(input_shape)\n",
    "        output = self.embedding.compute_output_shape(input_shape)\n",
    "        for encoder in self.enc_layers:\n",
    "            encoder.build(output)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.enc_layers[0].compute_output_shape(self.embedding.compute_output_shape(input_shape))\n",
    "\n",
    "    def call(self, inputs, mask=None, training=False):\n",
    "        attn_weights = None\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        for encoder in self.enc_layers:\n",
    "            x, attn_weights = encoder(x, mask=mask, training=training) \n",
    "        return x, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f10e565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:30.116700Z",
     "iopub.status.busy": "2025-05-05T19:59:30.116423Z",
     "iopub.status.idle": "2025-05-05T19:59:30.125183Z",
     "shell.execute_reply": "2025-05-05T19:59:30.124465Z"
    },
    "papermill": {
     "duration": 0.016986,
     "end_time": "2025-05-05T19:59:30.126527",
     "exception": false,
     "start_time": "2025-05-05T19:59:30.109541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DecoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model: int, h:int, d_ff: int, dropout_rate: float = 0.1, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.mhsa = MultiHeadAttention(self.d_model, self.h, self.dropout_rate)\n",
    "        self.add_norm1 = AddAndNorm()\n",
    "        self.mhca = MultiHeadAttention(self.d_model, self.h, self.dropout_rate)\n",
    "        self.add_norm2 = AddAndNorm()\n",
    "        self.pffn = PositionwiseFeedForwardNetwork(self.d_model, self.d_ff, self.dropout_rate)\n",
    "        self.add_norm3 = AddAndNorm()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dec_input_shape, enc_output_shape = input_shape\n",
    "        self.mhsa.build([dec_input_shape, dec_input_shape, dec_input_shape])\n",
    "        self.add_norm1.build(dec_input_shape)\n",
    "        self.mhca.build([dec_input_shape, enc_output_shape, enc_output_shape])\n",
    "        self.add_norm2.build(dec_input_shape)\n",
    "        self.pffn.build(dec_input_shape)\n",
    "        self.add_norm3.build(dec_input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        dec_input_shape, enc_output_shape = input_shape\n",
    "        return self.mhca.compute_output_shape([dec_input_shape, enc_output_shape, enc_output_shape])\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, decoder_mask=None, encoder_mask=None, training=False):\n",
    "        mhsa_outputs, _ = self.mhsa(inputs, inputs, inputs, mask=decoder_mask, training=training)\n",
    "        x = self.add_norm1(inputs, mhsa_outputs)\n",
    "        mhca_outputs, attn_weights = self.mhca(x, encoder_outputs, encoder_outputs, mask=encoder_mask, training=training)\n",
    "        x = self.add_norm2(x, mhca_outputs)\n",
    "        pffn_outputs = self.pffn(x, training=training)\n",
    "        x = self.add_norm3(x, pffn_outputs)\n",
    "\n",
    "        return x, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c0b9d7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:30.139596Z",
     "iopub.status.busy": "2025-05-05T19:59:30.139295Z",
     "iopub.status.idle": "2025-05-05T19:59:30.147945Z",
     "shell.execute_reply": "2025-05-05T19:59:30.147086Z"
    },
    "papermill": {
     "duration": 0.016886,
     "end_time": "2025-05-05T19:59:30.149345",
     "exception": false,
     "start_time": "2025-05-05T19:59:30.132459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, N: int, d_model: int, seq_len: int, voc_size: int, h:int, d_ff: int, dropout_rate: float = 0.1, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        assert N > 0\n",
    "        self.N = N\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.voc_size = voc_size\n",
    "        self.h = h\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.embedding = Embeddings(self.d_model, self.seq_len, self.voc_size, self.dropout_rate)\n",
    "        self.dec_layers = [DecoderBlock(self.d_model, self.h, self.d_ff, self.dropout_rate) for _ in range(self.N)]\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dec_input_shape, enc_output_shape = input_shape\n",
    "        self.embedding.build(dec_input_shape)\n",
    "        output = self.embedding.compute_output_shape(dec_input_shape)\n",
    "        for decoder in self.dec_layers:\n",
    "            decoder.build([output, enc_output_shape])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        dec_input_shape, enc_output_shape = input_shape\n",
    "        return self.dec_layers[0].compute_output_shape([self.embedding.compute_output_shape(dec_input_shape), enc_output_shape])\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, decoder_mask=None, encoder_mask=None, training=False):\n",
    "        attn_weights = None\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        for decoder in self.dec_layers:\n",
    "            x, attn_weights = decoder(x, encoder_outputs, decoder_mask=decoder_mask, encoder_mask=encoder_mask, training=training) \n",
    "        return x, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36dfd3d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:30.162846Z",
     "iopub.status.busy": "2025-05-05T19:59:30.162558Z",
     "iopub.status.idle": "2025-05-05T19:59:30.173226Z",
     "shell.execute_reply": "2025-05-05T19:59:30.172214Z"
    },
    "papermill": {
     "duration": 0.019612,
     "end_time": "2025-05-05T19:59:30.174970",
     "exception": false,
     "start_time": "2025-05-05T19:59:30.155358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Transformer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self, \n",
    "        encoder_layers: int, \n",
    "        decoder_layers: int,\n",
    "        d_model: int, \n",
    "        encoder_seq_len: int, \n",
    "        decoder_seq_len: int, \n",
    "        encoder_voc_size: int, \n",
    "        decoder_voc_size: int, \n",
    "        encoder_attention_heads: int, \n",
    "        decoder_attention_heads: int, \n",
    "        encoder_ffn_dim: int, \n",
    "        decoder_ffn_dim: int, \n",
    "        dropout: float = 0.1, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super(Transformer, self).__init__(**kwargs)\n",
    "        \n",
    "        self.encoder_layers = encoder_layers\n",
    "        self.decoder_layers = decoder_layers\n",
    "        assert self.encoder_layers > 0 and self.decoder_layers > 0, \"Encoder and Decoder must have atleast 1 layer\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.encoder_seq_len = encoder_seq_len\n",
    "        self.decoder_seq_len = decoder_seq_len\n",
    "        self.encoder_voc_size = encoder_voc_size\n",
    "        self.decoder_voc_size = decoder_voc_size\n",
    "        self.encoder_attention_heads = encoder_attention_heads\n",
    "        self.decoder_attention_heads = decoder_attention_heads\n",
    "        self.encoder_ffn_dim = encoder_ffn_dim\n",
    "        self.decoder_ffn_dim = decoder_ffn_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.encoder = Encoder(self.encoder_layers, self.d_model, self.encoder_seq_len, self.encoder_voc_size, self.encoder_attention_heads, self.encoder_ffn_dim, self.dropout)\n",
    "        self.decoder = Decoder(self.decoder_layers, self.d_model, self.decoder_seq_len, self.decoder_voc_size, self.decoder_attention_heads, self.decoder_ffn_dim, self.dropout)\n",
    "        self.projection = tf.keras.layers.Dense(decoder_voc_size)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        enc_input_shape, dec_input_shape = input_shape\n",
    "        self.encoder.build(enc_input_shape)\n",
    "        enc_output, _ = self.encoder.compute_output_shape(enc_input_shape)\n",
    "        self.decoder.build([dec_input_shape, enc_output])\n",
    "        dec_output, _ = self.decoder.compute_output_shape([dec_input_shape, enc_output])\n",
    "        self.projection.build(dec_output)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        enc_input_shape, dec_input_shape = input_shape\n",
    "        enc_output, enc_attn = self.encoder.compute_output_shape(enc_input_shape)\n",
    "        dec_output, dec_attn = self.decoder.compute_output_shape([dec_input_shape, enc_output])\n",
    "        return self.projection.compute_output_shape(dec_output), enc_attn, dec_attn\n",
    "\n",
    "    def call(self, encoder_inputs, decoder_inputs, encoder_mask=None, decoder_mask=None, training=False):\n",
    "        enc_outputs, enc_attn_wts = self.encoder(encoder_inputs, mask=encoder_mask, training=training)\n",
    "        dec_outputs, dec_attn_wts = self.decoder(decoder_inputs, enc_outputs, encoder_mask=encoder_mask, decoder_mask=decoder_mask, training=training)\n",
    "        logits = self.projection(dec_outputs)\n",
    "\n",
    "        return logits, enc_attn_wts, dec_attn_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a06a92f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:30.188799Z",
     "iopub.status.busy": "2025-05-05T19:59:30.188516Z",
     "iopub.status.idle": "2025-05-05T19:59:30.194360Z",
     "shell.execute_reply": "2025-05-05T19:59:30.193568Z"
    },
    "papermill": {
     "duration": 0.014389,
     "end_time": "2025-05-05T19:59:30.195729",
     "exception": false,
     "start_time": "2025-05-05T19:59:30.181340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def cross_entropy_loss(targets, output_dist, mask=None, label_smoothing=0.1):\n",
    "    targets = tf.keras.utils.to_categorical(targets, num_classes=output_dist.shape[-1])\n",
    "    scce_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction=None, label_smoothing=label_smoothing)\n",
    "    step_scce_loss = scce_loss(targets, output_dist)\n",
    "    if mask is not None:\n",
    "        step_scce_loss = tf.reduce_mean(tf.reduce_sum(step_scce_loss*mask, 1) / tf.reduce_sum(mask, 1))\n",
    "    return step_scce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ff6523d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:30.209175Z",
     "iopub.status.busy": "2025-05-05T19:59:30.208904Z",
     "iopub.status.idle": "2025-05-05T19:59:30.222317Z",
     "shell.execute_reply": "2025-05-05T19:59:30.221570Z"
    },
    "papermill": {
     "duration": 0.021937,
     "end_time": "2025-05-05T19:59:30.223697",
     "exception": false,
     "start_time": "2025-05-05T19:59:30.201760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class TransformerTrainer(tf.keras.Model):\n",
    "    def __init__(self, transformer: Transformer, label_smoothing: float = 0.1, **kwargs):\n",
    "        super(TransformerTrainer, self).__init__(**kwargs)\n",
    "        self.transformer = transformer\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.val_loss_tracker = tf.keras.metrics.Mean(name=\"val_loss\")\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        enc_input, dec_input, dec_output = input_shape\n",
    "        self.transformer.build([enc_input, dec_input])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        enc_input, dec_input, dec_output = input_shape\n",
    "        return self.transformer.compute_output_shape([enc_input, dec_input])\n",
    "\n",
    "    def compute_padding_mask(self, inp):\n",
    "        mask = tf.cast(tf.math.not_equal(inp, 0), tf.float32)\n",
    "        mask = mask[:, tf.newaxis, tf.newaxis, :]\n",
    "        return mask\n",
    "    \n",
    "    def compute_padding_lookahead_mask(self, decoder_inp):\n",
    "        mask = tf.cast(tf.math.equal(decoder_inp, 0), tf.float32)\n",
    "        mask = mask[:, tf.newaxis, tf.newaxis, :]\n",
    "        return tf.cast(tf.maximum(mask, 1 - tf.linalg.band_part(tf.ones((decoder_inp.shape[-1], decoder_inp.shape[-1])), -1, 0)) == 0, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoder_inputs, decoder_inputs, targets = inputs\n",
    "        encoder_mask = self.compute_padding_mask(encoder_inputs)\n",
    "        decoder_mask = self.compute_padding_lookahead_mask(decoder_inputs)\n",
    "\n",
    "        return transformer(encoder_inputs, decoder_inputs, encoder_mask, decoder_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, inputs):\n",
    "        encoder_inputs, decoder_inputs, targets = inputs\n",
    "\n",
    "        loss = None\n",
    "        encoder_mask = self.compute_padding_mask(encoder_inputs)\n",
    "        decoder_mask = self.compute_padding_lookahead_mask(decoder_inputs)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits, _, _ = self.transformer(encoder_inputs, decoder_inputs, encoder_mask, decoder_mask, training=True)\n",
    "            loss = self.loss(targets, logits, tf.cast(tf.math.not_equal(targets, 0), tf.float32), self.label_smoothing)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.transformer.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.transformer.trainable_variables))\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "\n",
    "        return {'loss': self.loss_tracker.result()}\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, inputs):\n",
    "        encoder_inputs, decoder_inputs, targets = inputs\n",
    "        encoder_mask = self.compute_padding_mask(encoder_inputs)\n",
    "        decoder_mask = self.compute_padding_lookahead_mask(decoder_inputs)\n",
    "        \n",
    "        logits, _, _ = self.transformer(encoder_inputs, decoder_inputs, encoder_mask, decoder_mask, training=False)\n",
    "        loss = self.loss(targets, logits, mask=tf.cast(tf.math.not_equal(targets, 0), tf.float32), label_smoothing=0.0)\n",
    "\n",
    "        self.val_loss_tracker.update_state(loss)\n",
    "\n",
    "        return {'loss': self.val_loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83d49aaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:30.237163Z",
     "iopub.status.busy": "2025-05-05T19:59:30.236843Z",
     "iopub.status.idle": "2025-05-05T19:59:31.574793Z",
     "shell.execute_reply": "2025-05-05T19:59:31.573830Z"
    },
    "papermill": {
     "duration": 1.346783,
     "end_time": "2025-05-05T19:59:31.576567",
     "exception": false,
     "start_time": "2025-05-05T19:59:30.229784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:59:30.248911: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "tformer = Transformer(parameters['ENCODER_LAYERS'], parameters['DECODER_LAYERS'], parameters['EMBEDDING_DIMENSION'], parameters['ENCODER_SEQUENCE_LENGTH'], parameters['DECODER_SEQUENCE_LENGTH'], parameters['VOC_SIZE'], parameters['VOC_SIZE'], parameters['ENCODER_ATTENTION_HEADS'], parameters['DECODER_ATTENTION_HEADS'], parameters['ENCODER_FFN_DIM'], parameters['DECODER_FFN_DIM'])\n",
    "model = TransformerTrainer(tformer, parameters['LABEL_SMOOTHING'])\n",
    "model.build(((None, parameters['ENCODER_SEQUENCE_LENGTH']), (None, parameters['DECODER_SEQUENCE_LENGTH']), (None, parameters['DECODER_SEQUENCE_LENGTH'])))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=parameters['LEARNING_RATE'], weight_decay=parameters['L2_REG']), loss=cross_entropy_loss, run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b397f449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:31.590195Z",
     "iopub.status.busy": "2025-05-05T19:59:31.589862Z",
     "iopub.status.idle": "2025-05-05T19:59:31.609778Z",
     "shell.execute_reply": "2025-05-05T19:59:31.608880Z"
    },
    "papermill": {
     "duration": 0.028534,
     "end_time": "2025-05-05T19:59:31.611336",
     "exception": false,
     "start_time": "2025-05-05T19:59:31.582802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_trainer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer_trainer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ transformer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Transformer</span>)            │ ((<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50000</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">55,881,552</span> │\n",
       "│                                      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, │                 │\n",
       "│                                      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>))                       │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ transformer (\u001b[38;5;33mTransformer\u001b[0m)            │ ((\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m50000\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,  │      \u001b[38;5;34m55,881,552\u001b[0m │\n",
       "│                                      │ \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m12\u001b[0m, │                 │\n",
       "│                                      │ \u001b[38;5;34m256\u001b[0m))                       │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,881,552</span> (213.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,881,552\u001b[0m (213.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,881,552</span> (213.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,881,552\u001b[0m (213.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22ed6dee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:31.627661Z",
     "iopub.status.busy": "2025-05-05T19:59:31.627377Z",
     "iopub.status.idle": "2025-05-05T19:59:33.705015Z",
     "shell.execute_reply": "2025-05-05T19:59:33.703885Z"
    },
    "papermill": {
     "duration": 2.087012,
     "end_time": "2025-05-05T19:59:33.706689",
     "exception": false,
     "start_time": "2025-05-05T19:59:31.619677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 518 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('/kaggle/input/headline-generator-outputs/transformer.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35b4a9d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:33.722676Z",
     "iopub.status.busy": "2025-05-05T19:59:33.722333Z",
     "iopub.status.idle": "2025-05-05T19:59:33.734678Z",
     "shell.execute_reply": "2025-05-05T19:59:33.733753Z"
    },
    "papermill": {
     "duration": 0.022739,
     "end_time": "2025-05-05T19:59:33.736449",
     "exception": false,
     "start_time": "2025-05-05T19:59:33.713710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def beam_generate(model, news, encoder_seq_len, decoder_seq_len, tokenizer, sos_id, eos_id, pad_id, beam_width=3, length_penalty=0.6):\n",
    "    news_encoded = tokenizer.encode(news)\n",
    "    \n",
    "    if len(news_encoded) >= encoder_seq_len:\n",
    "        news_encoded = news_encoded[:encoder_seq_len]\n",
    "    else:\n",
    "        news_encoded = news_encoded + [pad_id] * (encoder_seq_len - len(news_encoded))\n",
    "\n",
    "    encoder_mask = tf.cast(tf.math.not_equal([news_encoded], 0), tf.float32)\n",
    "    encoder_mask = encoder_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    enc_outputs, enc_attn_wts = model.transformer.encoder(tf.convert_to_tensor([news_encoded]), mask=encoder_mask, training=False)\n",
    "    \n",
    "    decoder_input = tf.fill([1,1], sos_id)\n",
    "    beams = [(0.0, decoder_input)]\n",
    "\n",
    "    for t in range(decoder_seq_len):\n",
    "\n",
    "        expanded_beam = []\n",
    "        for log_prob_score, sequence in beams:\n",
    "            if sequence[0, -1] == eos_id:\n",
    "                expanded_beam.append((log_prob_score, sequence))\n",
    "                continue\n",
    "        \n",
    "            decoder_mask = tf.cast(tf.math.equal(decoder_input, 0), tf.float32)\n",
    "            decoder_mask = decoder_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "            decoder_mask = tf.cast(tf.maximum(decoder_mask, 1 - tf.linalg.band_part(tf.ones((decoder_input.shape[-1], decoder_input.shape[-1])), -1, 0)) == 0, tf.float32)\n",
    "    \n",
    "            dec_outputs, dec_attn_wts = model.transformer.decoder(sequence, enc_outputs, encoder_mask=encoder_mask, decoder_mask=decoder_mask, training=False)\n",
    "            final_dist = model.transformer.projection(dec_outputs[:,-1])\n",
    "            log_prob_scores = tf.nn.log_softmax(final_dist, -1)\n",
    "            top_k_probs, top_k_idxs = tf.math.top_k(log_prob_scores, k=beam_width)\n",
    "            for i in range(beam_width):\n",
    "                new_seq = tf.concat([sequence, [[top_k_idxs[0, i]]]], axis=-1)\n",
    "                expanded_beam.append((log_prob_score+top_k_probs[0, i], new_seq))\n",
    "        \n",
    "        def normalized_score(candidate):\n",
    "            score, seq = candidate\n",
    "            length = tf.cast(tf.shape(seq)[1], tf.float32)\n",
    "\n",
    "            total_score = score / ((5+length) ** length_penalty / (5+1) ** length_penalty) \n",
    "            return total_score\n",
    "            \n",
    "        beams = sorted(expanded_beam, key=normalized_score, reverse=True)\n",
    "        beams = beams[:beam_width]\n",
    "        \n",
    "        if all(seq[0, -1].numpy() == eos_id for _, seq in beams):\n",
    "            break\n",
    "        \n",
    "    return tokenizer.decode(tf.squeeze(beams[0][1], 0).numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1b6b1c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:33.752420Z",
     "iopub.status.busy": "2025-05-05T19:59:33.751968Z",
     "iopub.status.idle": "2025-05-05T19:59:37.423459Z",
     "shell.execute_reply": "2025-05-05T19:59:37.422423Z"
    },
    "papermill": {
     "duration": 3.681693,
     "end_time": "2025-05-05T19:59:37.424963",
     "exception": false,
     "start_time": "2025-05-05T19:59:33.743270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('मोदीको चेतावनीकाबारेमा राष्ट्रपति कोविन्दलाई पत्र',\n",
       " 'मोदीद्वारा निर्वाचन बहिष्कार')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['title'].iloc[10], beam_generate(model, df_test['news'].iloc[10], parameters['ENCODER_SEQUENCE_LENGTH'], parameters['DECODER_SEQUENCE_LENGTH'], sp, parameters['SOS_TOKEN_ID'], parameters['EOS_TOKEN_ID'], parameters['PAD_TOKEN_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "033c6c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:37.439938Z",
     "iopub.status.busy": "2025-05-05T19:59:37.439600Z",
     "iopub.status.idle": "2025-05-05T19:59:37.448472Z",
     "shell.execute_reply": "2025-05-05T19:59:37.447492Z"
    },
    "papermill": {
     "duration": 0.018257,
     "end_time": "2025-05-05T19:59:37.450181",
     "exception": false,
     "start_time": "2025-05-05T19:59:37.431924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def greedy_generate(model, news, encoder_seq_len, decoder_seq_len, tokenizer, sos_id, eos_id, pad_id):\n",
    "    news_encoded = tokenizer.encode(news)\n",
    "    \n",
    "    if len(news_encoded) >= encoder_seq_len:\n",
    "        news_encoded = news_encoded[:encoder_seq_len]\n",
    "    else:\n",
    "        news_encoded = news_encoded + [pad_id] * (encoder_seq_len - len(news_encoded))\n",
    "\n",
    "    encoder_mask = tf.cast(tf.math.not_equal([news_encoded], 0), tf.float32)\n",
    "    encoder_mask = encoder_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    enc_outputs, enc_attn_wts = model.transformer.encoder(tf.convert_to_tensor([news_encoded]), mask=encoder_mask, training=False)\n",
    "    \n",
    "    decoder_input = tf.fill([1,1], sos_id)\n",
    "\n",
    "    for t in range(decoder_seq_len):\n",
    "        decoder_mask = tf.cast(tf.math.equal(decoder_input, 0), tf.float32)\n",
    "        decoder_mask = decoder_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "        decoder_mask = tf.cast(tf.maximum(decoder_mask, 1 - tf.linalg.band_part(tf.ones((decoder_input.shape[-1], decoder_input.shape[-1])), -1, 0)) == 0, tf.float32)\n",
    "\n",
    "        dec_outputs, dec_attn_wts = model.transformer.decoder(decoder_input, enc_outputs, encoder_mask=encoder_mask, decoder_mask=decoder_mask, training=False)\n",
    "        final_dist = model.transformer.projection(dec_outputs[:,-1])\n",
    "        curr_output = tf.expand_dims(tf.argmax(final_dist, -1, output_type=tf.int32), 1)\n",
    "        if curr_output[0] == eos_id:\n",
    "            break\n",
    "        decoder_input = tf.concat([decoder_input, curr_output], -1)\n",
    "\n",
    "    return tokenizer.decode(tf.squeeze(decoder_input, 0).numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f10b37ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:37.465762Z",
     "iopub.status.busy": "2025-05-05T19:59:37.465148Z",
     "iopub.status.idle": "2025-05-05T19:59:38.838616Z",
     "shell.execute_reply": "2025-05-05T19:59:38.837832Z"
    },
    "papermill": {
     "duration": 1.382827,
     "end_time": "2025-05-05T19:59:38.840166",
     "exception": false,
     "start_time": "2025-05-05T19:59:37.457339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('मोदीको चेतावनीकाबारेमा राष्ट्रपति कोविन्दलाई पत्र',\n",
       " 'मोदीद्वारा मोदीको आलोचना')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['title'].iloc[10], greedy_generate(model, df_test['news'].iloc[10], parameters['ENCODER_SEQUENCE_LENGTH'], parameters['DECODER_SEQUENCE_LENGTH'], sp, parameters['SOS_TOKEN_ID'], parameters['EOS_TOKEN_ID'], parameters['PAD_TOKEN_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97581aa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:38.856042Z",
     "iopub.status.busy": "2025-05-05T19:59:38.855696Z",
     "iopub.status.idle": "2025-05-05T19:59:38.867460Z",
     "shell.execute_reply": "2025-05-05T19:59:38.866652Z"
    },
    "papermill": {
     "duration": 0.022017,
     "end_time": "2025-05-05T19:59:38.869635",
     "exception": false,
     "start_time": "2025-05-05T19:59:38.847618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_val = df_val.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6c61cbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:59:38.886993Z",
     "iopub.status.busy": "2025-05-05T19:59:38.886646Z",
     "iopub.status.idle": "2025-05-05T21:51:25.408437Z",
     "shell.execute_reply": "2025-05-05T21:51:25.406989Z"
    },
    "papermill": {
     "duration": 6706.533365,
     "end_time": "2025-05-05T21:51:25.410851",
     "exception": false,
     "start_time": "2025-05-05T19:59:38.877486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_titles = []\n",
    "pred_titles_greedy = []\n",
    "pred_titles_beam3 = []\n",
    "for news, title in zip(df_val['news'], df_val['title']):\n",
    "    greedy_pred = greedy_generate(model, news, parameters['ENCODER_SEQUENCE_LENGTH'], parameters['DECODER_SEQUENCE_LENGTH'], sp, parameters['SOS_TOKEN_ID'], parameters['EOS_TOKEN_ID'], parameters['PAD_TOKEN_ID'])\n",
    "    beam_pred = beam_generate(model, news, parameters['ENCODER_SEQUENCE_LENGTH'], parameters['DECODER_SEQUENCE_LENGTH'], sp, parameters['SOS_TOKEN_ID'], parameters['EOS_TOKEN_ID'], parameters['PAD_TOKEN_ID'])\n",
    "    ref_titles.append(title)\n",
    "    pred_titles_greedy.append(greedy_pred)\n",
    "    pred_titles_beam3.append(beam_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dda334e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:51:25.429017Z",
     "iopub.status.busy": "2025-05-05T21:51:25.428662Z",
     "iopub.status.idle": "2025-05-05T21:51:29.199633Z",
     "shell.execute_reply": "2025-05-05T21:51:29.198407Z"
    },
    "papermill": {
     "duration": 3.781352,
     "end_time": "2025-05-05T21:51:29.201494",
     "exception": false,
     "start_time": "2025-05-05T21:51:25.420142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "def compute_bleu_metric(reference: list, predicted: list) -> float:\n",
    "    '''\n",
    "    Computes the BLEU metric given a set of refraence and predicted sequences of words\n",
    "    \n",
    "    :param list(str) refrence: List of refrence sequences. Eg: [\"Hi I am jane doe\", \"i am from italy\"]    \n",
    "    :param list(str) predicted: List of predicted sequences. Eg: [\"i jane doe\", \"i was born and raised in sicily\"]\n",
    "    :return: The BLEU score for the predicted sequences.\n",
    "    '''\n",
    "    return corpus_bleu([[value.split()] for value in reference], [value.split() for value in predicted], smoothing_function=smoothie, weights=(0.25, 0.25, 0.25, 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "418bca71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:51:29.220527Z",
     "iopub.status.busy": "2025-05-05T21:51:29.219449Z",
     "iopub.status.idle": "2025-05-05T21:51:29.290641Z",
     "shell.execute_reply": "2025-05-05T21:51:29.289564Z"
    },
    "papermill": {
     "duration": 0.083216,
     "end_time": "2025-05-05T21:51:29.292551",
     "exception": false,
     "start_time": "2025-05-05T21:51:29.209335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy BLEU Score: 0.0537\n"
     ]
    }
   ],
   "source": [
    "print(f\"Greedy BLEU Score: {compute_bleu_metric(ref_titles, pred_titles_greedy):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a347be98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:51:29.311191Z",
     "iopub.status.busy": "2025-05-05T21:51:29.310861Z",
     "iopub.status.idle": "2025-05-05T21:51:29.378432Z",
     "shell.execute_reply": "2025-05-05T21:51:29.376967Z"
    },
    "papermill": {
     "duration": 0.078014,
     "end_time": "2025-05-05T21:51:29.380062",
     "exception": false,
     "start_time": "2025-05-05T21:51:29.302048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam BLEU Score: 0.0536\n"
     ]
    }
   ],
   "source": [
    "print(f\"Beam BLEU Score: {compute_bleu_metric(ref_titles, pred_titles_beam3):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da4322fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:51:29.397761Z",
     "iopub.status.busy": "2025-05-05T21:51:29.397420Z",
     "iopub.status.idle": "2025-05-05T21:51:36.791299Z",
     "shell.execute_reply": "2025-05-05T21:51:36.789886Z"
    },
    "papermill": {
     "duration": 7.40513,
     "end_time": "2025-05-05T21:51:36.793419",
     "exception": false,
     "start_time": "2025-05-05T21:51:29.388289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install rouge --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0edd00fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:51:36.810282Z",
     "iopub.status.busy": "2025-05-05T21:51:36.809941Z",
     "iopub.status.idle": "2025-05-05T21:51:36.823141Z",
     "shell.execute_reply": "2025-05-05T21:51:36.821694Z"
    },
    "papermill": {
     "duration": 0.023459,
     "end_time": "2025-05-05T21:51:36.824930",
     "exception": false,
     "start_time": "2025-05-05T21:51:36.801471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "def compute_rouge_metric(reference: list, predicted: list) -> dict:\n",
    "    '''\n",
    "    Computes Rogue-1, Rouge-2 and Rouge-L metric given a set of refraence and predicted sequences of words\n",
    "    \n",
    "    :param list(str) refrence: List of refrence sequences. Eg: [\"Hi I am jane doe\", \"i am from italy\"]    \n",
    "    :param list(str) predicted: List of predicted sequences. Eg: [\"i jane doe\", \"i was born and raised in sicily\"]\n",
    "    :return: The rouge-1,2,L scores for the predicted sequences.\n",
    "    '''\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(predicted, reference, avg=True)\n",
    "    return {\n",
    "        \"Rouge-1\": scores['rouge-1']['f'],\n",
    "        \"Rouge-2\": scores['rouge-2']['f'],\n",
    "        \"Rouge-L\": scores['rouge-l']['f']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dae39b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:51:36.842000Z",
     "iopub.status.busy": "2025-05-05T21:51:36.840695Z",
     "iopub.status.idle": "2025-05-05T21:51:36.931032Z",
     "shell.execute_reply": "2025-05-05T21:51:36.930072Z"
    },
    "papermill": {
     "duration": 0.100435,
     "end_time": "2025-05-05T21:51:36.932725",
     "exception": false,
     "start_time": "2025-05-05T21:51:36.832290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rouge-1': 0.23565679721727883,\n",
       " 'Rouge-2': 0.08352211940603078,\n",
       " 'Rouge-L': 0.22773539076855046}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_rouge_metric(ref_titles, pred_titles_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2df313e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:51:36.954436Z",
     "iopub.status.busy": "2025-05-05T21:51:36.954106Z",
     "iopub.status.idle": "2025-05-05T21:51:37.044885Z",
     "shell.execute_reply": "2025-05-05T21:51:37.043888Z"
    },
    "papermill": {
     "duration": 0.100666,
     "end_time": "2025-05-05T21:51:37.046557",
     "exception": false,
     "start_time": "2025-05-05T21:51:36.945891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Rouge Score:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Rouge-1': 0.23565679721727883,\n",
       " 'Rouge-2': 0.08352211940603078,\n",
       " 'Rouge-L': 0.22773539076855046}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Greedy Rouge Score:\") \n",
    "compute_rouge_metric(ref_titles, pred_titles_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5d21f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:51:37.072108Z",
     "iopub.status.busy": "2025-05-05T21:51:37.071768Z",
     "iopub.status.idle": "2025-05-05T21:51:37.151070Z",
     "shell.execute_reply": "2025-05-05T21:51:37.150100Z"
    },
    "papermill": {
     "duration": 0.092362,
     "end_time": "2025-05-05T21:51:37.152911",
     "exception": false,
     "start_time": "2025-05-05T21:51:37.060549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam Rouge Score:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Rouge-1': 0.23833000087301937,\n",
       " 'Rouge-2': 0.0889112182991589,\n",
       " 'Rouge-L': 0.2324588635995602}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Beam Rouge Score:\") \n",
    "compute_rouge_metric(ref_titles, pred_titles_beam3)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7006724,
     "sourceId": 11219687,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7006736,
     "sourceId": 11219703,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7335034,
     "sourceId": 11686630,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6772.642843,
   "end_time": "2025-05-05T21:51:40.683530",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-05T19:58:48.040687",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
