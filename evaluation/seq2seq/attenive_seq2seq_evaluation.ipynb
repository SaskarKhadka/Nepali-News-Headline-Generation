{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3f1163e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:17.086492Z",
     "iopub.status.busy": "2025-05-05T20:07:17.086171Z",
     "iopub.status.idle": "2025-05-05T20:07:42.622861Z",
     "shell.execute_reply": "2025-05-05T20:07:42.621732Z"
    },
    "papermill": {
     "duration": 25.545831,
     "end_time": "2025-05-05T20:07:42.624711",
     "exception": false,
     "start_time": "2025-05-05T20:07:17.078880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 20:07:27.288876: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746475647.540994      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746475647.618672      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Input, Dense, TimeDistributed, Embedding, Concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f854a0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:42.637205Z",
     "iopub.status.busy": "2025-05-05T20:07:42.636566Z",
     "iopub.status.idle": "2025-05-05T20:07:42.697063Z",
     "shell.execute_reply": "2025-05-05T20:07:42.696055Z"
    },
    "papermill": {
     "duration": 0.068378,
     "end_time": "2025-05-05T20:07:42.698847",
     "exception": false,
     "start_time": "2025-05-05T20:07:42.630469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"/kaggle/input/nepali-summarization-tokenizer/summarization_50000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf5eecf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:42.711193Z",
     "iopub.status.busy": "2025-05-05T20:07:42.710792Z",
     "iopub.status.idle": "2025-05-05T20:07:42.717056Z",
     "shell.execute_reply": "2025-05-05T20:07:42.715956Z"
    },
    "papermill": {
     "duration": 0.014043,
     "end_time": "2025-05-05T20:07:42.718507",
     "exception": false,
     "start_time": "2025-05-05T20:07:42.704464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'VOC_SIZE': 50_000,\n",
    "\n",
    "    'ENCODER_SEQUENCE_LENGTH': 256,\n",
    "    'DECODER_SEQUENCE_LENGTH': 12,\n",
    "    \n",
    "    'EMBEDDING_DIMENSION': 100,\n",
    "    \n",
    "    'ENCODER_HIDDEN_DIM': 64,\n",
    "    'DECODER_HIDDEN_DIM': 128,\n",
    "    \n",
    "    'DROPOUT': 0.3,\n",
    "\n",
    "    'BATCH_SIZE': 128,\n",
    "    'EPOCHS': 16,\n",
    "    'EARLY_STOPPING': 3,\n",
    "    'L2_REG': 0.01,\n",
    "    \n",
    "    'LEARNING_RATE': 1e-3,\n",
    "    'GRAD_CLIP': 1.0,\n",
    "\n",
    "    'PAD_TOKEN': '<pad>',\n",
    "    'UNK_TOKEN': '<unk>',\n",
    "    'SOS_TOKEN': '<s>',\n",
    "    'EOS_TOKEN': '</s>',\n",
    "\n",
    "    'PAD_TOKEN_ID': sp.pad_id(),\n",
    "    'UNK_TOKEN_ID': sp.unk_id(),\n",
    "    'SOS_TOKEN_ID': sp.bos_id(),\n",
    "    'EOS_TOKEN_ID': sp.eos_id(),\n",
    "\n",
    "    'ATTENTION_TYPE': 'bahdanau',\n",
    "\n",
    "    'COVERAGE_WEIGHT': 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4851f39e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:42.730470Z",
     "iopub.status.busy": "2025-05-05T20:07:42.730161Z",
     "iopub.status.idle": "2025-05-05T20:07:44.321656Z",
     "shell.execute_reply": "2025-05-05T20:07:44.320618Z"
    },
    "papermill": {
     "duration": 1.599613,
     "end_time": "2025-05-05T20:07:44.323560",
     "exception": false,
     "start_time": "2025-05-05T20:07:42.723947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(\"/kaggle/input/nepali-summarization-set-cleaned/summarization_set_cleaned_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e910381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:44.336040Z",
     "iopub.status.busy": "2025-05-05T20:07:44.335645Z",
     "iopub.status.idle": "2025-05-05T20:07:44.347041Z",
     "shell.execute_reply": "2025-05-05T20:07:44.346166Z"
    },
    "papermill": {
     "duration": 0.019377,
     "end_time": "2025-05-05T20:07:44.348561",
     "exception": false,
     "start_time": "2025-05-05T20:07:44.329184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(BahdanauAttention, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    # def build(self, input_shape):\n",
    "        self.W = tf.keras.layers.Dense(self.units, use_bias=False)\n",
    "        self.U = tf.keras.layers.Dense(self.units, use_bias=False)\n",
    "        self.Wc = tf.keras.layers.Dense(self.units)\n",
    "        self.V = tf.keras.layers.Dense(1, use_bias=False)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        encoder_outputs, decoder_hidden_state = input_shape\n",
    "        self.W.build((decoder_hidden_state[0], 1, decoder_hidden_state[1]))\n",
    "        self.U.build(encoder_outputs)\n",
    "        self.Wc.build((encoder_outputs[0], encoder_outputs[1], 1, 1))\n",
    "        self.V.build(encoder_outputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        encoder_outputs, decoder_hidden_state = input_shape\n",
    "        return decoder_hidden_state, decoder_hidden_state, (decoder_hidden_state[0], decoder_hidden_state[1], 1, 1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        encoder_outputs, encoder_mask, decoder_hidden_state, coverage_vector = inputs  # Select the output for the current time step\n",
    "\n",
    "        score = tf.reduce_sum(self.V(tf.nn.tanh(self.W(tf.expand_dims(tf.expand_dims(decoder_hidden_state, 1), 1)) + self.U(tf.expand_dims(encoder_outputs, 2)) + self.Wc(coverage_vector))), (2, 3))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # attention_weights = tf.squeeze(attention_weights, 2) * encoder_mask\n",
    "        attention_weights = attention_weights * encoder_mask\n",
    "\n",
    "        for_renorm = tf.reduce_sum(attention_weights, 1)\n",
    "\n",
    "        attention_weights = attention_weights / tf.reshape(for_renorm, (-1, 1))\n",
    "\n",
    "        coverage_vector += tf.reshape(attention_weights, [tf.shape(encoder_outputs)[0], -1, 1, 1])\n",
    "\n",
    "        # Calculate the context vector\n",
    "        context_vector = tf.reduce_sum(tf.reshape(attention_weights, [tf.shape(encoder_outputs)[0], -1, 1, 1]) * tf.expand_dims(encoder_outputs, 2), (1, 2))\n",
    "        # print(context_vector, \"BEF\")\n",
    "        # context_vector = tf.reshape(context_vector, [-1, tf.shape(encoder_outputs)[-1]])\n",
    "        # print(context_vector, \"AFT\")\n",
    "        return context_vector, attention_weights, coverage_vector\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'units': self.units\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61765888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:44.360840Z",
     "iopub.status.busy": "2025-05-05T20:07:44.360076Z",
     "iopub.status.idle": "2025-05-05T20:07:44.369611Z",
     "shell.execute_reply": "2025-05-05T20:07:44.368800Z"
    },
    "papermill": {
     "duration": 0.017004,
     "end_time": "2025-05-05T20:07:44.371003",
     "exception": false,
     "start_time": "2025-05-05T20:07:44.353999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout_rate, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.encoder_embedding = Embedding(self.vocab_size, self.embedding_dim, mask_zero=True, name='News_Embedding')\n",
    "        self.encoder_lstm = Bidirectional(LSTM(self.hidden_dim, return_sequences=True, return_state=True, dropout=self.dropout_rate), name='Encoder_BiLSTM')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.encoder_embedding.build(input_shape)\n",
    "        lstm_input = self.encoder_embedding.compute_output_shape(input_shape)\n",
    "        self.encoder_lstm.build(lstm_input)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        lstm_input = self.encoder_embedding.compute_output_shape(input_shape)\n",
    "        out, hf, cf, hb, cb = self.encoder_lstm.compute_output_shape(lstm_input)\n",
    "        return out, out, (hf[0], hf[1]+hb[1]), (cf[0], cf[1]+cb[1]) \n",
    "    \n",
    "    def call(self, encoder_input, training=False):\n",
    "        encoder_embedding = self.encoder_embedding(encoder_input)\n",
    "\n",
    "        encoder_mask = tf.cast(self.encoder_embedding.compute_mask(encoder_input), tf.float32)\n",
    "        \n",
    "        encoder_output, state_h_fwd, state_c_fwd, state_h_bwd, state_c_bwd = self.encoder_lstm(encoder_embedding, training=training)\n",
    "        \n",
    "        state_h = tf.concat([state_h_fwd, state_h_bwd], -1)\n",
    "        state_c = tf.concat([state_c_fwd, state_c_bwd], -1)\n",
    "        \n",
    "        return encoder_output, encoder_mask, state_h, state_c\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'vocab_size': self.vocab_size,\n",
    "            'embedding_dim': self.embedding_dim,\n",
    "            'hidden_dim': self.hidden_dim,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdd56ea4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:44.383311Z",
     "iopub.status.busy": "2025-05-05T20:07:44.382998Z",
     "iopub.status.idle": "2025-05-05T20:07:44.394067Z",
     "shell.execute_reply": "2025-05-05T20:07:44.393173Z"
    },
    "papermill": {
     "duration": 0.018948,
     "end_time": "2025-05-05T20:07:44.395476",
     "exception": false,
     "start_time": "2025-05-05T20:07:44.376528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout_rate, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.decoder_embedding = Embedding(self.vocab_size, self.embedding_dim, mask_zero=True, name='Title_Embedding')\n",
    "        self.decoder_lstm = LSTM(self.hidden_dim, return_sequences=True, return_state=True, dropout=self.dropout_rate, name='Decoder_LSTM')\n",
    "        self.bahdanau_attention = BahdanauAttention(units=self.hidden_dim, name=\"Bahdanau_Attention\")  \n",
    "        self.decoder_dense = Dense(self.vocab_size, activation = 'softmax', name=\"Softmax_Layer\")\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        decoder_input, encoder_outputs = input_shape\n",
    "        self.decoder_embedding.build(decoder_input)\n",
    "        lstm_input = self.decoder_embedding.compute_output_shape(decoder_input)\n",
    "        self.decoder_lstm.build(lstm_input)\n",
    "        lstm_output, h, c = self.decoder_lstm.compute_output_shape(lstm_input)\n",
    "        self.bahdanau_attention.build((encoder_outputs, h))\n",
    "        cxt, attn, cvg = self.bahdanau_attention.compute_output_shape((encoder_outputs, h))\n",
    "        self.decoder_dense.build((cxt[0], cxt[1]+h[1]))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        decoder_input, encoder_outputs = input_shape\n",
    "        lstm_input = self.decoder_embedding.compute_output_shape(decoder_input)\n",
    "        lstm_output, h, c = self.decoder_lstm.compute_output_shape(lstm_input)\n",
    "        cxt, attn, cvg = self.bahdanau_attention.compute_output_shape((encoder_outputs, h))\n",
    "        dist = self.decoder_dense.compute_output_shape((cxt[0], cxt[1]+h[1]))\n",
    "        return dist, h, c, attn, cvg\n",
    "    \n",
    "    def call(self, decoder_input, encoder_output, encoder_mask, previous_states, coverage_vector, training=False):\n",
    "        \n",
    "        decoder_embedding = self.decoder_embedding(decoder_input)\n",
    "\n",
    "        decoder_output, state_h, state_c, = self.decoder_lstm(decoder_embedding, initial_state=previous_states, training=training)\n",
    "        context_vector, attention_weights, coverage_vector = self.bahdanau_attention([encoder_output, encoder_mask, state_h, coverage_vector])\n",
    "        final_decoder_output = self.decoder_dense(tf.concat([context_vector, state_h], -1))\n",
    "        \n",
    "        return final_decoder_output, state_h, state_c, attention_weights, coverage_vector\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'vocab_size': self.vocab_size,\n",
    "            'embedding_dim': self.embedding_dim,\n",
    "            'hidden_dim': self.hidden_dim,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dde1586",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:44.407953Z",
     "iopub.status.busy": "2025-05-05T20:07:44.407355Z",
     "iopub.status.idle": "2025-05-05T20:07:44.412955Z",
     "shell.execute_reply": "2025-05-05T20:07:44.411822Z"
    },
    "papermill": {
     "duration": 0.013342,
     "end_time": "2025-05-05T20:07:44.414507",
     "exception": false,
     "start_time": "2025-05-05T20:07:44.401165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def sparse_categorical_and_coverage_loss(targets, output_dist, attn_wts, coverage, coverage_weight=1):\n",
    "    scce_loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=None)\n",
    "    step_scce_loss = scce_loss(targets, output_dist)\n",
    "    step_cov_loss = tf.reduce_sum(tf.minimum(attn_wts, coverage), 1)\n",
    "\n",
    "    return tf.expand_dims(step_scce_loss, 1), tf.expand_dims(step_cov_loss, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1ebbb66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:44.426476Z",
     "iopub.status.busy": "2025-05-05T20:07:44.426043Z",
     "iopub.status.idle": "2025-05-05T20:07:44.447307Z",
     "shell.execute_reply": "2025-05-05T20:07:44.446332Z"
    },
    "papermill": {
     "duration": 0.028938,
     "end_time": "2025-05-05T20:07:44.448747",
     "exception": false,
     "start_time": "2025-05-05T20:07:44.419809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class AttentiveSeq2Seq(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, sos_token_id, teacher_forcing_ratio=0.5, coverage_weight=1.0, **kwargs):\n",
    "        super(AttentiveSeq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # self.loss_fn = loss\n",
    "        self.sos_token_id = sos_token_id\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.coverage_weight = coverage_weight\n",
    "\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.coverage_tracker = tf.keras.metrics.Mean(name=\"coverage_loss\")\n",
    "        self.val_loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.val_coverage_tracker = tf.keras.metrics.Mean(name=\"coverage_loss\")\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        encoder_input, decoder_input = input_shape\n",
    "        self.encoder.build(encoder_input)\n",
    "        encoder_outputs = self.encoder.compute_output_shape(encoder_input)\n",
    "        self.decoder.build((decoder_input, encoder_outputs[0]))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        encoder_input, decoder_input = input_shape\n",
    "        encoder_outputs = self.encoder.compute_output_shape(encoder_input)\n",
    "        decoder_outputs = self.decoder.compute_output_shape((decoder_input, encoder_outputs))\n",
    "        return encoder_outputs, decoder_outputs\n",
    "    \n",
    "    def call(self):\n",
    "        \"\"\"\n",
    "        Decoder Inputs: <sos>.....\n",
    "        Target: .....<eos>\n",
    "        \"\"\"\n",
    "\n",
    "        return self.encoder, self.decoder\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, inputs):\n",
    "\n",
    "        encoder_inputs, targets = inputs\n",
    "        loss = 0.\n",
    "        cov_loss = 0.\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            batch_loss = None\n",
    "            batch_cov_loss = None\n",
    "            target_mask = tf.cast(tf.math.not_equal(targets, 0), tf.float32)\n",
    "            \n",
    "            coverage_vector_next_t = tf.zeros([tf.shape(encoder_inputs)[0], tf.shape(encoder_inputs)[1], 1, 1], dtype=tf.float32)\n",
    "            decoder_input = tf.fill([tf.shape(encoder_inputs)[0],], self.sos_token_id)\n",
    "\n",
    "            encoder_outputs, encoder_mask, hidden, cell = self.encoder(encoder_inputs, training=True)\n",
    "            \n",
    "            for t in range(targets.shape[1]):\n",
    "                final_dist, hidden, cell, attn_weights, coverage_vector = self.decoder(tf.expand_dims(decoder_input, 1), encoder_outputs, encoder_mask, [hidden, cell], coverage_vector_next_t, training=True)\n",
    "                decoder_input = targets[:, t] if random.random() < self.teacher_forcing_ratio else tf.argmax(final_dist, 1)  \n",
    "\n",
    "                step_loss, step_cov_loss = self.loss(targets[:,t], final_dist, attn_weights, tf.squeeze(tf.squeeze(coverage_vector_next_t, 3), 2), self.coverage_weight)\n",
    "\n",
    "                if batch_loss is None:\n",
    "                    batch_loss = step_loss\n",
    "                    batch_cov_loss = step_cov_loss\n",
    "                else:\n",
    "                    batch_loss =tf.concat([batch_loss, step_loss], 1)\n",
    "                    batch_cov_loss =tf.concat([batch_cov_loss, step_cov_loss], 1)\n",
    "        \n",
    "                coverage_vector_next_t = coverage_vector                \n",
    "\n",
    "            loss = tf.reduce_mean(tf.reduce_sum(batch_loss*target_mask, 1) / tf.reduce_sum(target_mask, 1))\n",
    "            cov_loss = tf.reduce_mean(tf.reduce_sum(batch_cov_loss*target_mask, 1) / tf.reduce_sum(target_mask, 1))\n",
    "    \n",
    "            loss = loss + self.coverage_weight * cov_loss\n",
    "\n",
    "        variables = self.encoder.trainable_variables + self.decoder.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.coverage_tracker.update_state(cov_loss)\n",
    "\n",
    "        return {'loss': self.loss_tracker.result(), 'coverage_loss': self.coverage_tracker.result()}    \n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, inputs):\n",
    "        encoder_inputs, targets = inputs\n",
    "\n",
    "        batch_loss = None\n",
    "        batch_cov_loss = None\n",
    "        \n",
    "        target_mask = tf.cast(tf.math.not_equal(targets, 0), tf.float32)\n",
    "        \n",
    "        coverage_vector_next_t = tf.zeros([tf.shape(encoder_inputs)[0], tf.shape(encoder_inputs)[1], 1, 1], dtype=tf.float32)\n",
    "        decoder_input = tf.fill([tf.shape(encoder_inputs)[0],], self.sos_token_id)\n",
    "\n",
    "        encoder_outputs, encoder_mask, hidden, cell = self.encoder(encoder_inputs, training=False)\n",
    "        \n",
    "        for t in range(targets.shape[1]):\n",
    "            final_dist, hidden, cell, attn_weights, coverage_vector = self.decoder(tf.expand_dims(decoder_input, 1), encoder_outputs, encoder_mask, [hidden, cell], coverage_vector_next_t, training=False)\n",
    "            decoder_input = tf.argmax(final_dist, 1)  \n",
    "\n",
    "            step_loss, step_cov_loss = self.loss(targets[:,t], final_dist, attn_weights, tf.squeeze(tf.squeeze(coverage_vector_next_t, 3), 2), self.coverage_weight)\n",
    "\n",
    "            if batch_loss is None:\n",
    "                batch_loss = step_loss\n",
    "                batch_cov_loss = step_cov_loss\n",
    "            else:\n",
    "                batch_loss =tf.concat([batch_loss, step_loss], 1)\n",
    "                batch_cov_loss =tf.concat([batch_cov_loss, step_cov_loss], 1)\n",
    "    \n",
    "            coverage_vector_next_t = coverage_vector                \n",
    "                    \n",
    "        loss = tf.reduce_mean(tf.reduce_sum(batch_loss*target_mask, 1) / tf.reduce_sum(target_mask, 1))\n",
    "        cov_loss = tf.reduce_mean(tf.reduce_sum(batch_cov_loss*target_mask, 1) / tf.reduce_sum(target_mask, 1))\n",
    "\n",
    "        final_loss = loss + self.coverage_weight * cov_loss\n",
    "\n",
    "        self.val_loss_tracker.update_state(final_loss)\n",
    "        self.val_coverage_tracker.update_state(cov_loss)\n",
    "\n",
    "        return {'loss': self.val_loss_tracker.result(), 'coverage_loss': self.val_coverage_tracker.result()}    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'encoder': self.encoder,\n",
    "            'decoder': self.decoder,\n",
    "            'sos_token_id': self.sos_token_id,\n",
    "            'teacher_forcing_ratio': self.teacher_forcing_ratio,\n",
    "            'coverage_weight': self.coverage_weight,\n",
    "            'loss_tracker': self.loss_tracker,\n",
    "            'coverage_tracker': self.coverage_tracker,\n",
    "            'val_loss_tracker': self.val_loss_tracker,\n",
    "            'val_coverage_tracker': self.val_coverage_tracker\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a27c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:44.460365Z",
     "iopub.status.busy": "2025-05-05T20:07:44.459950Z",
     "iopub.status.idle": "2025-05-05T20:07:44.464697Z",
     "shell.execute_reply": "2025-05-05T20:07:44.463810Z"
    },
    "papermill": {
     "duration": 0.012492,
     "end_time": "2025-05-05T20:07:44.466402",
     "exception": false,
     "start_time": "2025-05-05T20:07:44.453910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "848cd590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:44.478625Z",
     "iopub.status.busy": "2025-05-05T20:07:44.478297Z",
     "iopub.status.idle": "2025-05-05T20:07:44.867415Z",
     "shell.execute_reply": "2025-05-05T20:07:44.866278Z"
    },
    "papermill": {
     "duration": 0.396951,
     "end_time": "2025-05-05T20:07:44.869208",
     "exception": false,
     "start_time": "2025-05-05T20:07:44.472257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 20:07:44.488392: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(parameters['VOC_SIZE'], parameters['EMBEDDING_DIMENSION'], parameters['ENCODER_HIDDEN_DIM'], parameters['DROPOUT'])\n",
    "decoder = Decoder(parameters['VOC_SIZE'], parameters['EMBEDDING_DIMENSION'], parameters['DECODER_HIDDEN_DIM'], parameters['DROPOUT'])    \n",
    "model = AttentiveSeq2Seq(encoder, decoder,parameters['SOS_TOKEN_ID'])\n",
    "model.build(((None, parameters['ENCODER_SEQUENCE_LENGTH']), (None, parameters['DECODER_SEQUENCE_LENGTH'])))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=parameters['LEARNING_RATE'], weight_decay=parameters['L2_REG']), loss=sparse_categorical_and_coverage_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b1cae75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:44.881211Z",
     "iopub.status.busy": "2025-05-05T20:07:44.880862Z",
     "iopub.status.idle": "2025-05-05T20:07:44.897810Z",
     "shell.execute_reply": "2025-05-05T20:07:44.896838Z"
    },
    "papermill": {
     "duration": 0.024468,
     "end_time": "2025-05-05T20:07:44.899202",
     "exception": false,
     "start_time": "2025-05-05T20:07:44.874734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"attentive_seq2_seq\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"attentive_seq2_seq\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)                    │ ((<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,084,480</span> │\n",
       "│                                      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │                 │\n",
       "│                                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>))                │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)                    │ ((<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50000</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">18,000,400</span> │\n",
       "│                                      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │                 │\n",
       "│                                      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>))    │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder (\u001b[38;5;33mEncoder\u001b[0m)                    │ ((\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │       \u001b[38;5;34m5,084,480\u001b[0m │\n",
       "│                                      │ \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │                 │\n",
       "│                                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m))                │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder (\u001b[38;5;33mDecoder\u001b[0m)                    │ ((\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50000\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │      \u001b[38;5;34m18,000,400\u001b[0m │\n",
       "│                                      │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │                 │\n",
       "│                                      │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m))    │                 │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,084,880</span> (88.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,084,880\u001b[0m (88.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,084,880</span> (88.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,084,880\u001b[0m (88.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "109a2a98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:44.912731Z",
     "iopub.status.busy": "2025-05-05T20:07:44.912376Z",
     "iopub.status.idle": "2025-05-05T20:07:45.572914Z",
     "shell.execute_reply": "2025-05-05T20:07:45.571755Z"
    },
    "papermill": {
     "duration": 0.670311,
     "end_time": "2025-05-05T20:07:45.575783",
     "exception": false,
     "start_time": "2025-05-05T20:07:44.905472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 38 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('/kaggle/input/headline-generator-outputs/seq2seq_best.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29d732dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:45.596168Z",
     "iopub.status.busy": "2025-05-05T20:07:45.595704Z",
     "iopub.status.idle": "2025-05-05T20:07:45.603511Z",
     "shell.execute_reply": "2025-05-05T20:07:45.602546Z"
    },
    "papermill": {
     "duration": 0.016546,
     "end_time": "2025-05-05T20:07:45.605005",
     "exception": false,
     "start_time": "2025-05-05T20:07:45.588459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def greedy_generate(model, news, encoder_seq_len, decoder_seq_len, tokenizer, sos_id, eos_id, pad_id):\n",
    "    news_encoded = tokenizer.encode(news)\n",
    "    \n",
    "    if len(news_encoded) >= encoder_seq_len:\n",
    "        news_encoded = news_encoded[:encoder_seq_len]\n",
    "    else:\n",
    "        news_encoded = news_encoded + [pad_id] * (encoder_seq_len - len(news_encoded))\n",
    "\n",
    "    output_seq = []\n",
    "\n",
    "    encoder_outputs, encoder_mask, hidden, cell = model.encoder(tf.convert_to_tensor([news_encoded]), training=False)\n",
    "\n",
    "    decoder_input = tf.fill([1,], sos_id)\n",
    "    coverage_vector = tf.zeros([1, encoder_seq_len,1, 1])\n",
    "    \n",
    "    for t in range(decoder_seq_len):\n",
    "        final_dist, hidden, cell, _, coverage_vector = model.decoder(tf.expand_dims(decoder_input, 1), encoder_outputs, encoder_mask, [hidden, cell], coverage_vector, training=False)\n",
    "        decoder_input = tf.argmax(final_dist, -1)\n",
    "        if decoder_input[0] == eos_id:\n",
    "            break\n",
    "        output_seq += decoder_input.numpy().tolist()\n",
    "    return tokenizer.decode(output_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76f61c20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:45.618897Z",
     "iopub.status.busy": "2025-05-05T20:07:45.618564Z",
     "iopub.status.idle": "2025-05-05T20:07:48.072601Z",
     "shell.execute_reply": "2025-05-05T20:07:48.071595Z"
    },
    "papermill": {
     "duration": 2.462835,
     "end_time": "2025-05-05T20:07:48.073935",
     "exception": false,
     "start_time": "2025-05-05T20:07:45.611100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'Bahdanau_Attention' (of type BahdanauAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('आफूले निष्पक्ष र पारदर्शी रूपमा काम गरेको धितोपत्र बोर्डका अध्यक्षको दाबी',\n",
       " 'पुँजी बजारका सबै सूचक')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['title'][10], greedy_generate(model, df_val['news'][10], 256, 12, sp, parameters['SOS_TOKEN_ID'], parameters['EOS_TOKEN_ID'], parameters['PAD_TOKEN_ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4da42982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:48.088518Z",
     "iopub.status.busy": "2025-05-05T20:07:48.087627Z",
     "iopub.status.idle": "2025-05-05T20:07:48.098178Z",
     "shell.execute_reply": "2025-05-05T20:07:48.097339Z"
    },
    "papermill": {
     "duration": 0.019288,
     "end_time": "2025-05-05T20:07:48.099505",
     "exception": false,
     "start_time": "2025-05-05T20:07:48.080217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def beam_generate(model, news, encoder_seq_len, decoder_seq_len, tokenizer, sos_id, eos_id, pad_id, beam_width=3, length_penalty=0.6, coverage_penalty=0.2):\n",
    "    news_encoded = tokenizer.encode(news)\n",
    "    \n",
    "    if len(news_encoded) >= encoder_seq_len:\n",
    "        news_encoded = news_encoded[:encoder_seq_len]\n",
    "    else:\n",
    "        news_encoded = news_encoded + [pad_id] * (encoder_seq_len - len(news_encoded))\n",
    "\n",
    "    output_seq = []\n",
    "\n",
    "    encoder_outputs, encoder_mask, hidden, cell = model.encoder(tf.convert_to_tensor([news_encoded]), training=False)\n",
    "\n",
    "    decoder_input = tf.fill([1,], sos_id)\n",
    "    coverage_vector = tf.zeros([1, encoder_seq_len,1,1])\n",
    "    beams = [(0.0, decoder_input, hidden, cell, coverage_vector)]\n",
    "    \n",
    "    for t in range(decoder_seq_len):\n",
    "        expanded_beam = []\n",
    "\n",
    "        for log_prob_score, sequence, hid, cell, cov in beams:\n",
    "            if sequence[-1] == eos_id:\n",
    "                expanded_beam.append((log_prob_score, sequence, hid, cell, cov))\n",
    "            final_dist, hidden, cell, _, coverage_vector = model.decoder(tf.expand_dims(sequence[-1:], 0), encoder_outputs, encoder_mask, [hid, cell], cov, training=False)\n",
    "            log_prob_scores = tf.nn.log_softmax(final_dist[0])\n",
    "            top_k_probs, top_k_idxs = tf.math.top_k(log_prob_scores, k=beam_width)\n",
    "\n",
    "            for i in range(beam_width):\n",
    "                new_seq = tf.concat([sequence, [top_k_idxs[i]]], axis=0)\n",
    "                expanded_beam.append((log_prob_score+top_k_probs[i], new_seq, hidden, cell, coverage_vector))\n",
    "\n",
    "        def normalized_score(candidate):\n",
    "            score, seq, _, _, cov = candidate\n",
    "            length = tf.cast(tf.shape(seq)[0], tf.float32)\n",
    "\n",
    "            # coverage = tf.squeeze(cov, axis=[0, 2, 3]) \n",
    "            # cov_penalty = tf.reduce_sum(tf.math.log(tf.minimum(coverage, 1.0) + 1e-8))\n",
    "\n",
    "            total_score = score / ((5.0 + length) ** length_penalty) / ((5.0 + 1.0) ** length_penalty)\n",
    "            return total_score\n",
    "\n",
    "        beams = sorted(expanded_beam, key=normalized_score, reverse=True)\n",
    "        beams = beams[:beam_width]\n",
    "\n",
    "        if all(seq[-1].numpy() == eos_id for _, seq, _, _, _ in beams):\n",
    "            break\n",
    "\n",
    "    return tokenizer.decode(beams[0][1][1:].numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f933cf4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:48.113585Z",
     "iopub.status.busy": "2025-05-05T20:07:48.112746Z",
     "iopub.status.idle": "2025-05-05T20:07:51.032670Z",
     "shell.execute_reply": "2025-05-05T20:07:51.031730Z"
    },
    "papermill": {
     "duration": 2.928964,
     "end_time": "2025-05-05T20:07:51.034542",
     "exception": false,
     "start_time": "2025-05-05T20:07:48.105578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('भारतीय प्रसिद्ध गायक एसपी बालासुब्रमण्यमको निधन',\n",
       " 'भारतका चर्चित कलाकार भारतीय निधन')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['title'][21], beam_generate(model, df_val['news'][21], 256, 12, sp, parameters['SOS_TOKEN_ID'], parameters['EOS_TOKEN_ID'], parameters['PAD_TOKEN_ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f91abcd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:51.048111Z",
     "iopub.status.busy": "2025-05-05T20:07:51.047403Z",
     "iopub.status.idle": "2025-05-05T20:07:51.058334Z",
     "shell.execute_reply": "2025-05-05T20:07:51.057244Z"
    },
    "papermill": {
     "duration": 0.020464,
     "end_time": "2025-05-05T20:07:51.061074",
     "exception": false,
     "start_time": "2025-05-05T20:07:51.040610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_val = df_val.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30767bce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:07:51.075270Z",
     "iopub.status.busy": "2025-05-05T20:07:51.074888Z",
     "iopub.status.idle": "2025-05-05T21:32:45.023444Z",
     "shell.execute_reply": "2025-05-05T21:32:45.022196Z"
    },
    "papermill": {
     "duration": 5093.957993,
     "end_time": "2025-05-05T21:32:45.025320",
     "exception": false,
     "start_time": "2025-05-05T20:07:51.067327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_titles = []\n",
    "pred_titles_greedy = []\n",
    "pred_titles_beam3 = []\n",
    "for news, title in zip(df_val['news'], df_val['title']):\n",
    "    greedy_pred = greedy_generate(model, news, parameters['ENCODER_SEQUENCE_LENGTH'], parameters['DECODER_SEQUENCE_LENGTH'], sp, parameters['SOS_TOKEN_ID'], parameters['EOS_TOKEN_ID'], parameters['PAD_TOKEN_ID'])\n",
    "    beam_pred = beam_generate(model, news, parameters['ENCODER_SEQUENCE_LENGTH'], parameters['DECODER_SEQUENCE_LENGTH'], sp, parameters['SOS_TOKEN_ID'], parameters['EOS_TOKEN_ID'], parameters['PAD_TOKEN_ID'])\n",
    "    ref_titles.append(title)\n",
    "    pred_titles_greedy.append(greedy_pred)\n",
    "    pred_titles_beam3.append(beam_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6433e4aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:32:45.040236Z",
     "iopub.status.busy": "2025-05-05T21:32:45.039891Z",
     "iopub.status.idle": "2025-05-05T21:32:47.040169Z",
     "shell.execute_reply": "2025-05-05T21:32:47.039229Z"
    },
    "papermill": {
     "duration": 2.00958,
     "end_time": "2025-05-05T21:32:47.041832",
     "exception": false,
     "start_time": "2025-05-05T21:32:45.032252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "def compute_bleu_metric(reference: list, predicted: list) -> float:\n",
    "    '''\n",
    "    Computes the BLEU metric given a set of refraence and predicted sequences of words\n",
    "    \n",
    "    :param list(str) refrence: List of refrence sequences. Eg: [\"Hi I am jane doe\", \"i am from italy\"]    \n",
    "    :param list(str) predicted: List of predicted sequences. Eg: [\"i jane doe\", \"i was born and raised in sicily\"]\n",
    "    :return: The BLEU score for the predicted sequences.\n",
    "    '''\n",
    "    return corpus_bleu([[value.split()] for value in reference], [value.split() for value in predicted], smoothing_function=smoothie, weights=(0.25, 0.25, 0.25, 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cd1e012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:32:47.055830Z",
     "iopub.status.busy": "2025-05-05T21:32:47.055190Z",
     "iopub.status.idle": "2025-05-05T21:32:47.113138Z",
     "shell.execute_reply": "2025-05-05T21:32:47.112254Z"
    },
    "papermill": {
     "duration": 0.066417,
     "end_time": "2025-05-05T21:32:47.114552",
     "exception": false,
     "start_time": "2025-05-05T21:32:47.048135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy BLEU Score: 0.0317\n"
     ]
    }
   ],
   "source": [
    "print(f\"Greedy BLEU Score: {compute_bleu_metric(ref_titles, pred_titles_greedy):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03bbf221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:32:47.128362Z",
     "iopub.status.busy": "2025-05-05T21:32:47.127956Z",
     "iopub.status.idle": "2025-05-05T21:32:47.184475Z",
     "shell.execute_reply": "2025-05-05T21:32:47.183539Z"
    },
    "papermill": {
     "duration": 0.065193,
     "end_time": "2025-05-05T21:32:47.185924",
     "exception": false,
     "start_time": "2025-05-05T21:32:47.120731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam BLEU Score: 0.0260\n"
     ]
    }
   ],
   "source": [
    "print(f\"Beam BLEU Score: {compute_bleu_metric(ref_titles, pred_titles_beam3):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "826a314d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:32:47.200740Z",
     "iopub.status.busy": "2025-05-05T21:32:47.200435Z",
     "iopub.status.idle": "2025-05-05T21:32:52.481786Z",
     "shell.execute_reply": "2025-05-05T21:32:52.480543Z"
    },
    "papermill": {
     "duration": 5.291066,
     "end_time": "2025-05-05T21:32:52.483637",
     "exception": false,
     "start_time": "2025-05-05T21:32:47.192571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install rouge --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "435700f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:32:52.497861Z",
     "iopub.status.busy": "2025-05-05T21:32:52.497527Z",
     "iopub.status.idle": "2025-05-05T21:32:52.509070Z",
     "shell.execute_reply": "2025-05-05T21:32:52.508053Z"
    },
    "papermill": {
     "duration": 0.020709,
     "end_time": "2025-05-05T21:32:52.510729",
     "exception": false,
     "start_time": "2025-05-05T21:32:52.490020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "def compute_rouge_metric(reference: list, predicted: list) -> dict:\n",
    "    '''\n",
    "    Computes Rogue-1, Rouge-2 and Rouge-L metric given a set of refraence and predicted sequences of words\n",
    "    \n",
    "    :param list(str) refrence: List of refrence sequences. Eg: [\"Hi I am jane doe\", \"i am from italy\"]    \n",
    "    :param list(str) predicted: List of predicted sequences. Eg: [\"i jane doe\", \"i was born and raised in sicily\"]\n",
    "    :return: The rouge-1,2,L scores for the predicted sequences.\n",
    "    '''\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(predicted, reference, avg=True)\n",
    "    return {\n",
    "        \"Rouge-1\": scores['rouge-1']['f'],\n",
    "        \"Rouge-2\": scores['rouge-2']['f'],\n",
    "        \"Rouge-L\": scores['rouge-l']['f']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd7c765c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:32:52.525784Z",
     "iopub.status.busy": "2025-05-05T21:32:52.525477Z",
     "iopub.status.idle": "2025-05-05T21:32:52.604020Z",
     "shell.execute_reply": "2025-05-05T21:32:52.603225Z"
    },
    "papermill": {
     "duration": 0.087897,
     "end_time": "2025-05-05T21:32:52.605526",
     "exception": false,
     "start_time": "2025-05-05T21:32:52.517629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rouge-1': 0.19154094099732077,\n",
       " 'Rouge-2': 0.04900627078774634,\n",
       " 'Rouge-L': 0.1867987962139995}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_rouge_metric(ref_titles, pred_titles_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8410eae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:32:52.619706Z",
     "iopub.status.busy": "2025-05-05T21:32:52.619426Z",
     "iopub.status.idle": "2025-05-05T21:32:52.697900Z",
     "shell.execute_reply": "2025-05-05T21:32:52.697029Z"
    },
    "papermill": {
     "duration": 0.087607,
     "end_time": "2025-05-05T21:32:52.699479",
     "exception": false,
     "start_time": "2025-05-05T21:32:52.611872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Rouge Score:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Rouge-1': 0.19154094099732077,\n",
       " 'Rouge-2': 0.04900627078774634,\n",
       " 'Rouge-L': 0.1867987962139995}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Greedy Rouge Score:\") \n",
    "compute_rouge_metric(ref_titles, pred_titles_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c24b580",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T21:32:52.713568Z",
     "iopub.status.busy": "2025-05-05T21:32:52.713269Z",
     "iopub.status.idle": "2025-05-05T21:32:52.787386Z",
     "shell.execute_reply": "2025-05-05T21:32:52.786493Z"
    },
    "papermill": {
     "duration": 0.08314,
     "end_time": "2025-05-05T21:32:52.789083",
     "exception": false,
     "start_time": "2025-05-05T21:32:52.705943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam Rouge Score:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Rouge-1': 0.18098599260407947,\n",
       " 'Rouge-2': 0.04581363570384322,\n",
       " 'Rouge-L': 0.17680485903176935}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Beam Rouge Score:\") \n",
    "compute_rouge_metric(ref_titles, pred_titles_beam3)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7006724,
     "sourceId": 11219687,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7006736,
     "sourceId": 11219703,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7335034,
     "sourceId": 11686630,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5143.463581,
   "end_time": "2025-05-05T21:32:55.880398",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-05T20:07:12.416817",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
